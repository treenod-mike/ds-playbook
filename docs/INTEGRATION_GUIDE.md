# GraphRAG ì‹œìŠ¤í…œ í†µí•© ê°€ì´ë“œ

**ì‘ì„±ì¼**: 2026-01-30
**ë²„ì „**: v3.0
**ëª©ì **: test_chatbot_v2.py + rag_answer_generator.py í†µí•© ë° ì‹œìŠ¤í…œ íë¦„ ê°œì„ 

---

## ğŸ“‹ í†µí•© ê°œìš”

### í†µí•© ëª©í‘œ

1. **ì½”ë“œ ì¤‘ë³µ ì œê±°**: ë‘ ì‹œìŠ¤í…œì˜ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ë¡œì§ í†µí•©
2. **ì¼ê´€ì„± í™•ë³´**: ì›¹ í”Œë«í¼ê³¼ CLI ì±—ë´‡ì˜ ë™ì¼í•œ ë‹µë³€ ìƒì„± ë¡œì§
3. **ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ**: ë‹¨ì¼ ì†ŒìŠ¤ of truthë¡œ ê´€ë¦¬

### í†µí•© ì „í›„ ë¹„êµ

#### Before (v2.0)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  test_chatbot_v2.py          â”‚
â”‚  â”œâ”€ build_graph_context()    â”‚  â† ìì²´ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
â”‚  â””â”€ generate_system_prompt() â”‚  â† ìì²´ í”„ë¡¬í”„íŠ¸ ìƒì„±
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  rag_answer_generator.py     â”‚
â”‚  â”œâ”€ RAGContextFormatter      â”‚  â† ë³„ë„ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
â”‚  â””â”€ RAGAnswerGenerator       â”‚  â† ë³„ë„ ë‹µë³€ ìƒì„±
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ë¬¸ì œì :
- ì»¨í…ìŠ¤íŠ¸ ìƒì„± ë¡œì§ ì¤‘ë³µ
- í”„ë¡¬í”„íŠ¸ ë¶ˆì¼ì¹˜ ê°€ëŠ¥ì„±
- ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€
```

#### After (v3.0)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  test_chatbot_v3_integrated.py                      â”‚
â”‚  â”œâ”€ RAGContextFormatter (ì¬ì‚¬ìš©)                   â”‚
â”‚  â”‚   â””â”€ build_full_context() â†’ XML êµ¬ì¡°            â”‚
â”‚  â”‚                                                   â”‚
â”‚  â”œâ”€ RAGAnswerGenerator (ì¬ì‚¬ìš©)                    â”‚
â”‚  â”‚   â”œâ”€ SYSTEM_PROMPT (Evidence-based)             â”‚
â”‚  â”‚   â””â”€ generate_answer() â†’ ê·¼ê±° ê¸°ë°˜ ë‹µë³€         â”‚
â”‚  â”‚                                                   â”‚
â”‚  â””â”€ GraphRAGChatbotV3 (í†µí•© ë¡œì§)                  â”‚
â”‚      â”œâ”€ get_subgraph() (BFS íƒìƒ‰ ìœ ì§€)              â”‚
â”‚      â”œâ”€ _convert_chunks_to_search_results()         â”‚
â”‚      â”œâ”€ _convert_edges_to_graph_relations()         â”‚
â”‚      â””â”€ chat() (6ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ + RAG í†µí•©)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ì¥ì :
âœ… ì½”ë“œ ì¤‘ë³µ ì œê±°
âœ… ì¼ê´€ëœ ë‹µë³€ í’ˆì§ˆ
âœ… ë‹¨ì¼ ì†ŒìŠ¤ ìœ ì§€ë³´ìˆ˜
```

---

## ğŸ”„ ì£¼ìš” ë³€ê²½ ì‚¬í•­

### 1. ì»¨í…ìŠ¤íŠ¸ ìƒì„± ë¡œì§ êµì²´

#### Before (v2.0)
```python
# test_chatbot_v2.py
def build_graph_context(self, mentioned_terms, subgraph):
    """ê·¸ë˜í”„ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
    context = f"\n\n## ğŸ¯ ì§€ì‹ ê·¸ë˜í”„ ì •ë³´\n\n"
    context += f"**ì¤‘ì‹¬ ê°œë…**: {center_term}\n\n"
    # ... ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ...
    return context
```

**ë¬¸ì œì **:
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ (êµ¬ì¡°í™” ë¶€ì¡±)
- LLMì´ ì¶œì²˜ ì‹ë³„ ì–´ë ¤ì›€
- ë©”íƒ€ë°ì´í„° ëˆ„ë½

#### After (v3.0)
```python
# test_chatbot_v3_integrated.py
from src.core.generators.rag_answer_generator import RAGContextFormatter

# ì´ˆê¸°í™”
self.formatter = RAGContextFormatter()

# XML êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
vector_results = self._convert_chunks_to_search_results(subgraph['chunks'])
graph_relations = self._convert_edges_to_graph_relations(subgraph)

# RAGContextFormatter ì‚¬ìš© (ì¬ì‚¬ìš©)
context = self.formatter.build_full_context(
    query=user_message,
    vector_results=vector_results,
    graph_relations=graph_relations,
    ontology_rules=self.ontology_rules,
    center_term=center_term
)
```

**ê°œì„ ì **:
- XML êµ¬ì¡° (ëª…í™•í•œ ì¶œì²˜)
- ë©”íƒ€ë°ì´í„° í¬í•¨ (chunk_id, doc_title, confidence)
- LLMì´ ì •ë³´ ì‹ë³„ ìš©ì´

### 2. ë‹µë³€ ìƒì„± ë¡œì§ êµì²´

#### Before (v2.0)
```python
# test_chatbot_v2.py
system_prompt = self.generate_system_prompt(graph_context)

messages = [{"role": "system", "content": system_prompt}]
messages.extend(self.conversation_history[-10:])
messages.append({"role": "user", "content": user_message})

response = self.openai_client.chat.completions.create(
    model="gpt-4o",
    messages=messages,
    max_tokens=1024,
    temperature=0.7
)
```

**ë¬¸ì œì **:
- ìì²´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì¼ê´€ì„± ë¶€ì¡±)
- ì¶œì²˜ í‘œê¸° ê·œì¹™ ë¯¸ì •ì˜
- Hallucination ë°©ì§€ ë¯¸í¡

#### After (v3.0)
```python
# test_chatbot_v3_integrated.py
from src.core.generators.rag_answer_generator import RAGAnswerGenerator

# ì´ˆê¸°í™”
self.generator = RAGAnswerGenerator(self.openai_client)

# RAGAnswerGenerator ì‚¬ìš© (ì¬ì‚¬ìš©)
result = self.generator.generate_answer(
    query=user_message,
    vector_results=vector_results,
    graph_relations=graph_relations,
    ontology_rules=self.ontology_rules,
    center_term=center_term,
    temperature=0.3  # ë³´ìˆ˜ì  ìƒì„±
)

if result["success"]:
    assistant_message = result["answer"]
    # ë©”íƒ€ë°ì´í„° í™œìš© ê°€ëŠ¥
    print(f"ì‚¬ìš© í† í°: {result['metadata']['tokens_used']}")
```

**ê°œì„ ì **:
- Evidence-based ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í‘œì¤€í™”)
- ì¶œì²˜ í‘œê¸° ê°•ì œ (`[Source: ...]`)
- Hallucination ë°©ì§€ ê°•í™”
- Temperature 0.3 (ì¼ê´€ëœ ë‹µë³€)

### 3. ë°ì´í„° ë³€í™˜ í—¬í¼ ë©”ì„œë“œ ì¶”ê°€

#### ì²­í¬ ë³€í™˜
```python
def _convert_chunks_to_search_results(self, chunk_ids):
    """ì²­í¬ ID ëª©ë¡ì„ SearchResult ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    results = []
    for chunk_id in chunk_ids[:5]:  # ìµœëŒ€ 5ê°œ
        chunk_result = self.supabase.table('playbook_chunks')\
            .select("chunk_id, doc_id, content")\
            .eq("chunk_id", chunk_id)\
            .limit(1)\
            .execute()

        if chunk_result.data:
            chunk = chunk_result.data[0]
            doc_result = self.supabase.table('playbook_documents')\
                .select("title")\
                .eq("doc_id", chunk['doc_id'])\
                .limit(1)\
                .execute()

            doc_title = doc_result.data[0]['title'] if doc_result.data else "Unknown"

            results.append(SearchResult(
                chunk_id=chunk['chunk_id'],
                doc_id=chunk['doc_id'],
                doc_title=doc_title,
                content=chunk['content'],
                similarity=0.85  # ì‹œë®¬ë ˆì´ì…˜
            ))

    return results
```

#### ê´€ê³„ ë³€í™˜
```python
def _convert_edges_to_graph_relations(self, subgraph):
    """ì„œë¸Œê·¸ë˜í”„ì˜ edgesë¥¼ GraphRelation ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    relations = []

    for edge in subgraph.get('unique_edges', [])[:10]:  # ìµœëŒ€ 10ê°œ
        relations.append(GraphRelation(
            source=edge['source'],
            predicate=edge['predicate'],
            target=edge['target'],
            confidence=edge['confidence']
        ))

    return relations
```

---

## ğŸ“Š v3.0 ì‹œìŠ¤í…œ íë¦„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Input                                â”‚
â”‚               "ë™ì  ë‚œì´ë„ê°€ ë­ì•¼?"                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Term Matching (ìš©ì–´ ë§¤ì¹­)                                â”‚
â”‚  find_related_terms()                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Graph Traversal (ê·¸ë˜í”„ íƒìƒ‰)                            â”‚
â”‚  get_subgraph(center_term, radius=2)                         â”‚
â”‚  â””â”€ BFS 2-hop íƒìƒ‰                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Hop Path Analysis (ê²½ë¡œ ë¶„ì„)                            â”‚
â”‚  hop1_paths, hop2_paths ì‹œê°í™”                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Reasoning Chain (ì¶”ë¡  ì²´ì¸)                              â”‚
â”‚  reasoning_chain ìƒì„±                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Data Conversion (ë°ì´í„° ë³€í™˜)                            â”‚
â”‚  â”œâ”€ _convert_chunks_to_search_results()                     â”‚
â”‚  â”‚   â†’ SearchResult[]                                        â”‚
â”‚  â””â”€ _convert_edges_to_graph_relations()                     â”‚
â”‚      â†’ GraphRelation[]                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. Context Formatting (ì»¨í…ìŠ¤íŠ¸ êµ¬ì¡°í™”)                     â”‚
â”‚  RAGContextFormatter.build_full_context()                    â”‚
â”‚  â””â”€ XML êµ¬ì¡° ìƒì„±                                            â”‚
â”‚      <Context>                                                â”‚
â”‚        <VectorSearchResults>...</VectorSearchResults>         â”‚
â”‚        <GraphRelations>...</GraphRelations>                   â”‚
â”‚        <OntologyRules>...</OntologyRules>                     â”‚
â”‚      </Context>                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. Answer Generation (ë‹µë³€ ìƒì„±)                            â”‚
â”‚  RAGAnswerGenerator.generate_answer()                        â”‚
â”‚  â”œâ”€ System Prompt: Evidence-based BI Analyst                â”‚
â”‚  â”œâ”€ Temperature: 0.3                                         â”‚
â”‚  â””â”€ Citation: [Source: ...], [Graph: ...]                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  8. Output with Evidence (ê·¼ê±° í¬í•¨ ì¶œë ¥)                    â”‚
â”‚  â”œâ”€ ë‹µë³€: assistant_message                                  â”‚
â”‚  â””â”€ ë©”íƒ€ë°ì´í„°:                                              â”‚
â”‚      - ì‚¬ìš©ëœ ì²­í¬: 3ê°œ                                      â”‚
â”‚      - ì‚¬ìš©ëœ ê´€ê³„: 5ê°œ                                      â”‚
â”‚      - ì‚¬ìš© í† í°: 1,245                                      â”‚
â”‚      - ëŒ€í™” ì»¨í…ìŠ¤íŠ¸: [ë™ì  ë‚œì´ë„, ëª°ì…, ë¦¬í…ì…˜]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

### 1. v3.0 ì±—ë´‡ ì‹¤í–‰

```bash
python3 scripts/test_chatbot_v3_integrated.py
```

**í™˜ì˜ ë©”ì‹œì§€**:
```
======================================================================
PokoPoko v3.0 GraphRAG ì±—ë´‡ (Evidence-based Answer Generation)
======================================================================

ğŸ“¡ Supabase ì—°ê²° ì¤‘...
âœ… Supabase ì—°ê²° ì™„ë£Œ

ğŸ¤– OpenAI ì—°ê²° ì¤‘...
âœ… OpenAI ì—°ê²° ì™„ë£Œ

ğŸ“š ì˜¨í†¨ë¡œì§€ ë°ì´í„° ë¡œë“œ ì¤‘...
âœ… ìš©ì–´ 15056ê°œ, ì˜¨í†¨ë¡œì§€ ë£° 116ê°œ ë¡œë“œ

ğŸ’¬ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.

ì•ˆë…•í•˜ì„¸ìš”! PokoPoko ê²Œì„ì˜ ì§€ì‹ ê·¸ë˜í”„ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ê²Œì„ ë©”ì¹´ë‹‰, ì´ë²¤íŠ¸, UX, ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”!
v3.0: Evidence-based ë‹µë³€ ìƒì„± + XML êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸

You:
```

### 2. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

#### ì¼€ì´ìŠ¤ 1: ê¸°ë³¸ ì§ˆì˜
```
You: ë™ì  ë‚œì´ë„ê°€ ë­ì•¼?
```

**ê¸°ëŒ€ ê²°ê³¼**:
- âœ… ìš©ì–´ ë§¤ì¹­ ì„±ê³µ
- âœ… ê·¸ë˜í”„ íƒìƒ‰ (Hop 1, 2)
- âœ… XML ì»¨í…ìŠ¤íŠ¸ ìƒì„±
- âœ… Evidence-based ë‹µë³€ (ì¶œì²˜ í¬í•¨)

#### ì¼€ì´ìŠ¤ 2: ë³µí•© ì§ˆì˜
```
You: í´ë¡œë²„ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€?
```

**ê¸°ëŒ€ ê²°ê³¼**:
- âœ… ì—¬ëŸ¬ ê´€ê³„ íƒìƒ‰ (consumes, requires, drains ë“±)
- âœ… ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
- âœ… ì¶œì²˜ í‘œê¸° (`[Source: ...]`)

#### ì¼€ì´ìŠ¤ 3: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
```
You: ë™ì  ë‚œì´ë„ê°€ ë­ì•¼?
Assistant: [ë‹µë³€]
You: ê·¸ëŸ¼ ë¦¬í…ì…˜ì„ ë†’ì´ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•´?
```

**ê¸°ëŒ€ ê²°ê³¼**:
- âœ… ì´ì „ ëŒ€í™” ìš©ì–´ ê¸°ì–µ (ë™ì  ë‚œì´ë„)
- âœ… ê´€ê³„ ì²´ì¸ í™œìš© (ë™ì  ë‚œì´ë„ â†’ ëª°ì… â†’ ë¦¬í…ì…˜)

### 3. ë¹„êµ í…ŒìŠ¤íŠ¸

#### v2.0 vs v3.0 ë¹„êµ

| í•­ëª© | v2.0 | v3.0 | ê°œì„  |
|-----|------|------|------|
| ì»¨í…ìŠ¤íŠ¸ í˜•ì‹ | ë§ˆí¬ë‹¤ìš´ | XML | âœ… êµ¬ì¡°í™” |
| ì¶œì²˜ í‘œê¸° | ë¯¸í¡ | ê°•ì œ | âœ… ì‹ ë¢°ì„± |
| Hallucination | ê°€ëŠ¥ | ë°©ì§€ | âœ… ì •í™•ë„ |
| ì½”ë“œ ì¤‘ë³µ | ìˆìŒ | ì—†ìŒ | âœ… ìœ ì§€ë³´ìˆ˜ |
| Temperature | 0.7 | 0.3 | âœ… ì¼ê´€ì„± |

**í…ŒìŠ¤íŠ¸ ë°©ë²•**:
```bash
# v2.0 ì‹¤í–‰
python3 scripts/test_chatbot_v2.py
> ë™ì  ë‚œì´ë„ê°€ ë­ì•¼?

# v3.0 ì‹¤í–‰
python3 scripts/test_chatbot_v3_integrated.py
> ë™ì  ë‚œì´ë„ê°€ ë­ì•¼?

# ë‹µë³€ ë¹„êµ
# - ì¶œì²˜ í‘œê¸° ì—¬ë¶€
# - ë‹µë³€ ë…¼ë¦¬ì„±
# - ê·¼ê±° ëª…í™•ì„±
```

---

## ğŸš€ ì›¹ í”Œë«í¼ í†µí•© ë°©ì•ˆ

### 1. FastAPI ì—”ë“œí¬ì¸íŠ¸ ìˆ˜ì •

```python
# src/api/main.py

from src.core.generators.rag_answer_generator import (
    RAGAnswerGenerator,
    RAGContextFormatter,
    SearchResult,
    GraphRelation
)

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
formatter = RAGContextFormatter()
generator = RAGAnswerGenerator(openai_client)

@app.post("/api/chat")
async def chat(query: str):
    """ì±—ë´‡ API (v3.0: RAG Generator í†µí•©)"""

    # 1. ìš©ì–´ ì¶”ì¶œ
    mentioned_terms = find_related_terms(query)

    # 2. ê·¸ë˜í”„ íƒìƒ‰
    subgraph = get_subgraph(mentioned_terms[0]['term'], radius=2)

    # 3. ë°ì´í„° ë³€í™˜
    vector_results = convert_chunks_to_search_results(subgraph['chunks'])
    graph_relations = convert_edges_to_graph_relations(subgraph)

    # 4. ë‹µë³€ ìƒì„± (RAG Generator ì‚¬ìš©)
    result = generator.generate_answer(
        query=query,
        vector_results=vector_results,
        graph_relations=graph_relations,
        ontology_rules=ontology_rules,
        center_term=mentioned_terms[0]['term'],
        temperature=0.3
    )

    if result["success"]:
        return {
            "answer": result["answer"],
            "metadata": result["metadata"],
            "reasoning": {
                "hop_paths": subgraph['hop_paths'],
                "reasoning_chain": subgraph['reasoning_chain']
            }
        }
    else:
        return {"error": result["error"]}
```

### 2. ìŠ¤íŠ¸ë¦¬ë° API

```python
from fastapi.responses import StreamingResponse

@app.post("/api/chat/stream")
async def chat_stream(query: str):
    """ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ API"""

    # ... ë°ì´í„° ì¤€ë¹„ (ë™ì¼) ...

    def generate():
        for token in generator.generate_answer_streaming(
            query=query,
            vector_results=vector_results,
            graph_relations=graph_relations,
            ontology_rules=ontology_rules,
            center_term=center_term
        ):
            yield token

    return StreamingResponse(generate(), media_type="text/plain")
```

### 3. í”„ë¡ íŠ¸ì—”ë“œ í†µí•© (Next.js)

```typescript
// playbook-web/src/components/Chat.tsx

async function sendMessage(query: string) {
  const response = await fetch('/api/chat', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ query })
  });

  const data = await response.json();

  // ë‹µë³€ í‘œì‹œ
  setMessages([...messages, {
    role: 'assistant',
    content: data.answer,
    metadata: data.metadata,
    reasoning: data.reasoning
  }]);
}

// ìŠ¤íŠ¸ë¦¬ë° ë²„ì „
async function sendMessageStreaming(query: string) {
  const response = await fetch('/api/chat/stream', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ query })
  });

  const reader = response.body?.getReader();
  let accumulated = '';

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    accumulated += new TextDecoder().decode(value);
    setCurrentMessage(accumulated);
  }
}
```

---

## ğŸ“ ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: ë¡œì»¬ í…ŒìŠ¤íŠ¸
- [ ] v3.0 ì±—ë´‡ ì‹¤í–‰ ì„±ê³µ
- [ ] ê¸°ë³¸ ì§ˆì˜ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë³µí•© ì§ˆì˜ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ í™•ì¸
- [ ] v2.0 ëŒ€ë¹„ í’ˆì§ˆ ê°œì„  í™•ì¸

### Phase 2: API í†µí•©
- [ ] FastAPI ì—”ë“œí¬ì¸íŠ¸ ìˆ˜ì •
- [ ] ìŠ¤íŠ¸ë¦¬ë° API êµ¬í˜„
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ì¶”ê°€
- [ ] API í…ŒìŠ¤íŠ¸ ì‘ì„±

### Phase 3: ì›¹ í”Œë«í¼ í†µí•©
- [ ] í”„ë¡ íŠ¸ì—”ë“œ API í˜¸ì¶œ ìˆ˜ì •
- [ ] ìŠ¤íŠ¸ë¦¬ë° UI êµ¬í˜„
- [ ] ë‹µë³€ ë©”íƒ€ë°ì´í„° í‘œì‹œ
- [ ] ì¶”ë¡  ê³¼ì • ì‹œê°í™”

### Phase 4: í”„ë¡œë•ì…˜ ë°°í¬
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸
- [ ] ëª¨ë‹ˆí„°ë§ ì„¤ì •
- [ ] ë°°í¬ ë° ê²€ì¦

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: SearchResult ë³€í™˜ ì‹¤íŒ¨

**ì¦ìƒ**: `_convert_chunks_to_search_results()` ì—ì„œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

**ì›ì¸**: `source_chunks` í•„ë“œê°€ ë¹„ì–´ìˆìŒ

**í•´ê²°**:
```python
# Phase 1 ì‹¤í–‰ ì‹œ source_chunks ì €ì¥ í™•ì¸
# semantic_processor.pyì—ì„œ source_chunks í•„ë“œ ì—…ë°ì´íŠ¸ ë¡œì§ ì¶”ê°€
```

### ë¬¸ì œ 2: ë‹µë³€ì— ì¶œì²˜ ì—†ìŒ

**ì¦ìƒ**: ë‹µë³€ì— `[Source: ...]` í‘œê¸° ì—†ìŒ

**ì›ì¸**: LLMì´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¬´ì‹œ

**í•´ê²°**:
```python
# Temperature ë‚®ì¶”ê¸°
result = generator.generate_answer(..., temperature=0.2)

# ë˜ëŠ” í”„ë¡¬í”„íŠ¸ ê°•í™”
# RAGAnswerGenerator.SYSTEM_PROMPTì—ì„œ Citation ê·œì¹™ ê°•ì¡°
```

### ë¬¸ì œ 3: v2.0 ëŒ€ë¹„ ëŠë¦° ì‘ë‹µ

**ì¦ìƒ**: v3.0ì´ v2.0ë³´ë‹¤ ëŠë¦¼

**ì›ì¸**: XML íŒŒì‹± ì˜¤ë²„í—¤ë“œ

**í•´ê²°**:
```python
# ì²­í¬/ê´€ê³„ ìˆ˜ ì œí•œ
vector_results = self._convert_chunks_to_search_results(subgraph['chunks'][:3])  # 5â†’3
graph_relations = self._convert_edges_to_graph_relations(subgraph)[:5]  # 10â†’5
```

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md) - í”„ë¡œì íŠ¸ êµ¬ì¡° ë° ì‹œìŠ¤í…œ íë¦„
- [RAG_ANSWER_GENERATION.md](RAG_ANSWER_GENERATION.md) - RAG ë‹µë³€ ìƒì„± ê°€ì´ë“œ
- [ONTOLOGY_UPDATE_SUMMARY.md](../ONTOLOGY_UPDATE_SUMMARY.md) - v2.0 ì˜¨í†¨ë¡œì§€ ì—…ê·¸ë ˆì´ë“œ

---

**ë¬¸ì˜**: í†µí•© ê´€ë ¨ ì§ˆë¬¸ì€ ì´ìŠˆ ë“±ë¡ ë˜ëŠ” ë‹´ë‹¹ìì—ê²Œ ì—°ë½í•˜ì„¸ìš”.
