# Playbook Nexus: GraphRAG for Business Intelligence

**"ì¡°ì§ì˜ ì•”ë¬µì§€ë¥¼ AIê°€ ì´í•´í•˜ê³  ì¶”ë¡ í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ì „í™˜í•˜ëŠ” ì§€ì‹ ì¸í”„ë¼"**

Playbook NexusëŠ” ì „í†µì ì¸ RAGë¥¼ ë„˜ì–´ì„  **GraphRAG(Graph-based Retrieval-Augmented Generation)** ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ë‹¨ìˆœíˆ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì„ ë„˜ì–´, **ì—”í‹°í‹° ê°„ì˜ ê´€ê³„ì™€ ì¸ê³¼ë¥¼ ì¶”ë¡ **í•  ìˆ˜ ìˆëŠ” ì§€ì‹ ê·¸ë˜í”„ë¥¼ êµ¬ì¶•í•˜ì—¬, AIê°€ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì´í•´í•˜ê³  ë³µì¡í•œ ì˜ì‚¬ê²°ì •ì„ ì§€ì›í•©ë‹ˆë‹¤.

## ëª©ì°¨
- [ì™œ GraphRAGì¸ê°€?](#ì™œ-graphragì¸ê°€)
- [ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸](#ë¹„ì¦ˆë‹ˆìŠ¤-ì„íŒ©íŠ¸)
- [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
- [Phase 1: Semantic Extraction](#phase-1-semantic-extraction)
- [Phase 2: Knowledge Graph Construction](#phase-2-knowledge-graph-construction)
  - [í•µì‹¬ ê°œì„ ì‚¬í•­ (2025-01-21)](#í•µì‹¬-ê°œì„ ì‚¬í•­-2025-01-21-update-)
- [Phase 3: Graph Traversal](#phase-3-graph-traversal-ê·¸ë˜í”„-íƒìƒ‰) ğŸ†•
- [FastAPI ì„œë²„ ë°°í¬](#-fastapi-ì„œë²„-ë°°í¬) ğŸ†•
- [ì„¤ì¹˜ ë° ì„¤ì •](#ì„¤ì¹˜-ë°-ì„¤ì •)
- [ì‚¬ìš©ë²•](#ì‚¬ìš©ë²•)
- [ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ](#ë°ì´í„°ë² ì´ìŠ¤-ìŠ¤í‚¤ë§ˆ)
- [í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§](#í”„ë¡¬í”„íŠ¸-ì—”ì§€ë‹ˆì–´ë§)
- [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
- [ë³€ê²½ ì´ë ¥](#ë³€ê²½-ì´ë ¥)

---

## ì™œ GraphRAGì¸ê°€?

### ì „í†µì  RAGì˜ í•œê³„
```
ì§ˆë¬¸: "í­íƒ„ì´ë€ ë¬´ì—‡ì¸ê°€?"
ë‹µë³€: [ë²¡í„° ê²€ìƒ‰] â†’ "í­íƒ„ì€ ì£¼ë³€ ë¸”ë¡ì„ ì œê±°í•˜ëŠ” íŠ¹ìˆ˜ ì•„ì´í…œì…ë‹ˆë‹¤."
```
â†’ **ë‹¨ìˆœ ì •ë³´ ì œê³µ**, ê´€ê³„ë‚˜ íŒŒê¸‰íš¨ê³¼ë¥¼ ì•Œ ìˆ˜ ì—†ìŒ

### GraphRAGì˜ ëŠ¥ë ¥
```
ì§ˆë¬¸: "í­íƒ„ ë°ë¯¸ì§€ë¥¼ 20% ì¦ê°€ì‹œí‚¤ë©´ ê²Œì„ ë°¸ëŸ°ìŠ¤ì— ì–´ë–¤ ì˜í–¥ì´ ìˆë‚˜ìš”?"
ë‹µë³€: [ê·¸ë˜í”„ ì¶”ì ]
  1. í­íƒ„ (ë°ë¯¸ì§€ ì¦ê°€)
  2. â†“ clears â†’ ë°”ìœ„/ì–¼ìŒ (ì œê±° ì†ë„ ì¦ê°€)
  3. â†“ ë‚œì´ë„ í•˜ë½
  4. â†“ í´ë¡œë²„ ì†Œë¹„ ê°ì†Œ (ì¬ë„ì „ íšŸìˆ˜â†“)
  5. â†“ ë§¤ì¶œ ì˜í–¥ ì˜ˆì¸¡
```
â†’ **2ì°¨, 3ì°¨ íŒŒê¸‰íš¨ê³¼ê¹Œì§€ ì¶”ë¡  ê°€ëŠ¥**

---

## ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸

### ì •ëŸ‰ì  íš¨ê³¼
| ì§€í‘œ | Before | After | ê°œì„ ìœ¨ |
|------|--------|-------|--------|
| **ì‹ ì… ì˜¨ë³´ë”©** | 6ê°œì›” | 2ì£¼ | ğŸ”¥ **92%** |
| **ê¸°íš ê²€ì¦ ì‹œê°„** | 2ì£¼ | 1ì¼ | ğŸ”¥ **93%** |
| **ì§€ì‹ ì†ì‹¤ë¥ ** (í‡´ì‚¬ ì‹œ) | 80% | 10% | âœ… **90%** |

### ì •ì„±ì  íš¨ê³¼
1. **ì˜ì‚¬ê²°ì • í’ˆì§ˆ**: AIê°€ ë³µì¡í•œ ì¸ê³¼ê´€ê³„ë¥¼ ì¶”ì í•˜ì—¬ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ë¶€ì‘ìš© ì‚¬ì „ íƒì§€
2. **í¬ë¡œìŠ¤ ë„ë©”ì¸ ì¸ì‚¬ì´íŠ¸**: "ë‹¤ë¥¸ ê²Œì„ì˜ ìœ ì‚¬ ì‹œìŠ¤í…œ íŒ¨í„´ì€?" ê°™ì€ ì°½ì˜ì  ì§ˆë¬¸ ê°€ëŠ¥
3. **í˜‘ì—… íš¨ìœ¨**: ìš©ì–´ í‘œì¤€í™”ë¡œ ê¸°íšì-ê°œë°œì-ì•„íŠ¸ ê°„ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë¹„ìš© ê°ì†Œ

### Use Case ì˜ˆì‹œ
```
Q: "í´ë¡œë²„ íšŒë³µ ì‹œê°„ì„ 30ë¶„â†’60ë¶„ìœ¼ë¡œ ëŠ˜ë¦¬ë©´?"
A: [GraphRAG ë¶„ì„]
   í´ë¡œë²„ (íšŒë³µ ì‹œê°„â†‘)
   â†“ consumes (by ìŠ¤í…Œì´ì§€)
   â†“ í”Œë ˆì´ ë¹ˆë„â†“
   â†“ ì²´ë¦¬ íšë“â†“ (rewards from ìŠ¤í…Œì´ì§€)
   â†“ ì•„ì´í…œ êµ¬ë§¤ ê°€ëŠ¥ì„±â†“
   â†’ ì˜ˆìƒ ë§¤ì¶œ ì˜í–¥: -15%
```

---

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### GraphRAG = Traditional RAG + Knowledge Graph

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TIER 1: Traditional RAG                  â”‚
â”‚  (ë²¡í„° ê²€ìƒ‰ - "í­íƒ„ì´ë€ ë¬´ì—‡ì¸ê°€?" ê°™ì€ ë‹¨ìˆœ ì§ˆë¬¸)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Confluence â†’ Chunks â†’ Embeddings â†’ Vector Search           â”‚
â”‚                                                              â”‚
â”‚  playbook_documents  (ì›ë³¸ ë¬¸ì„œ)                             â”‚
â”‚  playbook_chunks     (ì²­í¬ + 1536ì°¨ì› ë²¡í„°)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   TIER 2: Knowledge Graph                   â”‚
â”‚  (ê´€ê³„ ì¶”ë¡  - "í­íƒ„ ë²„í”„ ì‹œ ë°¸ëŸ°ìŠ¤ ì˜í–¥ì€?" ê°™ì€ ë³µí•© ì§ˆë¬¸)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Terms â†’ Ontology Rules â†’ Relations â†’ Graph Traversal       â”‚
â”‚                                                              â”‚
â”‚  playbook_semantic_terms      (ë…¸ë“œ: ìš©ì–´ ì‚¬ì „)              â”‚
â”‚  playbook_ontology_rules      (ìŠ¤í‚¤ë§ˆ: ê´€ê³„ ë²•ì¹™)            â”‚
â”‚  playbook_semantic_relations  (ì—£ì§€: ì‹¤ì œ ê´€ê³„)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5-Table Architecture

1. **playbook_documents**: Confluence ì›ë³¸ ë¬¸ì„œ (ì œëª©, URL, ë©”íƒ€ë°ì´í„°)
2. **playbook_chunks**: í…ìŠ¤íŠ¸ ì²­í¬ + OpenAI ì„ë² ë”© (1536ì°¨ì›)
3. **playbook_semantic_terms**: ì¶”ì¶œëœ ìš©ì–´ (ì˜ˆ: "í­íƒ„", "í´ë¡œë²„") + ì¹´í…Œê³ ë¦¬
4. **playbook_ontology_rules**: AI í™˜ê° ë°©ì§€ ê·œì¹™ (ì˜ˆ: `Mechanic triggers GameObject`)
5. **playbook_semantic_relations**: ì‹¤ì œ ê´€ê³„ (ì˜ˆ: "4ë§¤ì¹˜" --triggers--> "í­íƒ„")

---

## ì£¼ìš” íŠ¹ì§•

### Phase 1: Semantic Extraction (ìš©ì–´ ì¶”ì¶œ)
- âœ… **11,606ì ì´ˆì •ë°€ í”„ë¡¬í”„íŠ¸**: PokoPoko ë„ë©”ì¸ ì „ë¬¸ ì˜¨í†¨ë¡œì§€ ì¶”ì¶œ
- âœ… **5ê°œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜**: GameObject, Resource, Mechanic, Content, Condition
- âœ… **raw_relations ì €ì¥**: 1ì°¨ ì¶”ì¶œëœ ê´€ê³„ë¥¼ JSONBë¡œ ë°±ì—…
- âœ… **ë™ì˜ì–´ ì²˜ë¦¬**: "í´ë¡œë²„" = "í•˜íŠ¸" = "ìŠ¤íƒœë¯¸ë‚˜" ìë™ í†µí•©

### Phase 2: Graph Construction (ê·¸ë˜í”„ êµ¬ì¶•)
- âœ… **ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ê²€ì¦**: 10ê°œ ê²Œì„ ê·œì¹™ìœ¼ë¡œ AI í™˜ê° ë°©ì§€
- âœ… **Confidence Scoring**: 4ë‹¨ê³„ ëª…í™•í•œ ê¸°ì¤€ (0.9-1.0/0.7-0.9/0.5-0.7/<0.5)
- âœ… **Negative Examples**: 3ê°€ì§€ ì¶”ì¶œ ê¸ˆì§€ ì¼€ì´ìŠ¤ ëª…ì‹œ
- âœ… **Evidence Tracking**: ëª¨ë“  ê´€ê³„ê°€ ì›ë¬¸ ê·¼ê±° ë³´ìœ 

### Technical Excellence
- âœ… **íŒŒì¼ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬**: ì½”ë“œ ë°°í¬ ì—†ì´ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ê°€ëŠ¥
- âœ… **UUID ê¸°ë°˜ ID**: ë¶„ì‚° ì‹œìŠ¤í…œ ëŒ€ì‘
- âœ… **JSONB ì¸ë±ìŠ¤**: raw_relations ë¹ ë¥¸ ê²€ìƒ‰
- âœ… **Batch Processing**: 50ê°œì”© UPSERTë¡œ ì„±ëŠ¥ ìµœì í™”

---

## Phase 1: Semantic Extraction

### ëª©ì 
ë¬¸ì„œì—ì„œ **ìš©ì–´(Term)**ì™€ **1ì°¨ ê´€ê³„(raw_relations)**ë¥¼ ì¶”ì¶œí•˜ì—¬ `playbook_semantic_terms` í…Œì´ë¸”ì— ì €ì¥

### ì‹¤í–‰ ë°©ë²•
```bash
# Phase 1ë§Œ ì‹¤í–‰
python3 main.py --max-pages 10

# Phase 1 + Phase 2 ì—°ì† ì‹¤í–‰
python3 main.py --max-pages 10 --phase2
```

### ì²˜ë¦¬ íë¦„
```
Confluence API
    â†“
ë¬¸ì„œ ìˆ˜ì§‘ (HTML â†’ Plain Text)
    â†“
Header-Aware ì²­í‚¹ (100-2000ì, ë¬¸ì¥ ê²½ê³„ ë³´ì¡´)
    â†“
OpenAI ì„ë² ë”© ìƒì„± (text-embedding-3-small, 1536ì°¨ì›)
    â†“
LLM ê¸°ë°˜ ìš©ì–´ ì¶”ì¶œ (prompts/system_pokopoko.md)
    â†“
playbook_semantic_terms ì €ì¥ (term, category, definition, raw_relations)
```

### ì¶”ì¶œ ì˜ˆì‹œ

**ì…ë ¥ í…ìŠ¤íŠ¸**:
```
4ê°œì˜ ë¸”ë¡ì„ ë§¤ì¹­í•˜ë©´ í­íƒ„ì´ ìƒì„±ë©ë‹ˆë‹¤.
í­íƒ„ì€ ì£¼ë³€ 3x3 ë²”ìœ„ì˜ ë¸”ë¡ì„ ì œê±°í•©ë‹ˆë‹¤.
```

**ì¶”ì¶œ ê²°ê³¼**:
```json
{
  "term": "í­íƒ„",
  "category": "GameObject",
  "definition": "ì£¼ë³€ 3x3 ë²”ìœ„ ë¸”ë¡ì„ ì œê±°í•˜ëŠ” íŠ¹ìˆ˜ ì•„ì´í…œ",
  "confidence": 0.98,
  "raw_relations": [
    {"target": "ë¸”ë¡", "type": "clears", "confidence": 0.98, "desc": "3x3 ë²”ìœ„ ì œê±°"},
    {"target": "4ë§¤ì¹˜", "type": "requires", "confidence": 0.95, "desc": "ìƒì„± ì¡°ê±´"}
  ]
}
```

### í•µì‹¬ íŒŒì¼
- `semantic_processor.py`: ì¶”ì¶œ ë¡œì§
- `prompts/system_pokopoko.md`: 11,606ì ì˜¨í†¨ë¡œì§€ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸

---

## Phase 2: Knowledge Graph Construction

### ëª©ì 
Phase 1ì˜ `raw_relations`ë¥¼ ê²€ì¦í•˜ì—¬ `playbook_semantic_relations` í…Œì´ë¸”ì— ê·¸ë˜í”„ êµ¬ì¶•

### ì‹¤í–‰ ë°©ë²•
```bash
# Phase 2ë§Œ ë³„ë„ ì‹¤í–‰
python3 ontology_builder.py --max-docs 5

# main.pyì—ì„œ Phase 1 í›„ ìë™ ì‹¤í–‰
python3 main.py --max-pages 10 --phase2
```

### ì²˜ë¦¬ íë¦„
```
playbook_semantic_terms ë¡œë“œ (raw_relations í¬í•¨)
    â†“
playbook_ontology_rules ë¡œë“œ (10ê°œ ê²Œì„ ê·œì¹™)
    â†“
ê° ë¬¸ì„œë³„ ì²˜ë¦¬:
  1. raw_relationsì˜ target ìš©ì–´ê°€ DBì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
  2. ê´€ê³„ê°€ ontology rulesì— ë¶€í•©í•˜ëŠ”ì§€ ê²€ì¦
     (ì˜ˆ: Mechanic triggers GameObject âœ…)
  3. Confidence threshold ì²´í¬ (ìµœì†Œ 0.5)
    â†“
ê²€ì¦ëœ ê´€ê³„ë§Œ playbook_semantic_relationsì— ì €ì¥
```

### ê²€ì¦ ì˜ˆì‹œ

**raw_relation**:
```json
{"target": "í­íƒ„", "type": "triggers", "confidence": 0.95}
```

**ê²€ì¦ ê³¼ì •**:
1. âœ… **ìš©ì–´ ë§¤ì¹­**: "í­íƒ„"ì´ playbook_semantic_termsì— ì¡´ì¬í•˜ëŠ”ê°€?
2. âœ… **ì˜¨í†¨ë¡œì§€ ê·œì¹™**: `Mechanic triggers GameObject` ê·œì¹™ì´ ì¡´ì¬í•˜ëŠ”ê°€?
3. âœ… **Confidence**: 0.95 > 0.5 (threshold)
4. â†’ **í†µê³¼**: playbook_semantic_relationsì— ì €ì¥

### í•µì‹¬ ê°œì„ ì‚¬í•­ (2025-01-21 Update) â­

#### 1. Definition Fallback Logic
**íŒŒì¼**: `semantic_processor.py` (lines 511-532)

**ë¬¸ì œ**: LLMì´ definitionì„ ì œê³µí•˜ì§€ ì•Šìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ì €ì¥

**í•´ê²°ì±…**: 3ë‹¨ê³„ Fallback
1. Contextì˜ ì²« 100ì ì‚¬ìš©
2. Evidence chunk snippet ì‚¬ìš©
3. Placeholder: "{term} (ì •ì˜ ì—†ìŒ)"

**íš¨ê³¼**: Definition ì™„ì„±ë„ 50% â†’ **100%**

#### 2. Enhanced Term Matching (ê°€ì¥ ì¤‘ìš”) ğŸ”¥
**íŒŒì¼**: `ontology_builder.py` (lines 33-86, 167-233)

**2A. í•œêµ­ì–´ ì¡°ì‚¬ ì œê±°**
```python
normalize_term("ë”ë¸”í­íƒ„ì€") â†’ "ë”ë¸”í­íƒ„"
normalize_term("í´ë¡œë²„ë¥¼") â†’ "í´ë¡œë²„"
normalize_term("ë”ë¸” í­íƒ„") â†’ "ë”ë¸”í­íƒ„"  # ë„ì–´ì“°ê¸°ë„ ì œê±°
```

**ì¡°ì‚¬ ëª©ë¡**: ì€/ëŠ”/ì´/ê°€/ì„/ë¥¼/ì™€/ê³¼/ì˜/ì—/ì—ì„œ/ìœ¼ë¡œ/ë¡œ/ë„/ë§Œ/ë¶€í„°/ê¹Œì§€ (17ê°œ)

**2B. Fuzzy Matching**
```python
def fuzzy_match_term(query, candidates):
    # 1. Exact match (ì •ê·œí™” í›„)
    # 2. Substring match (ë¶€ë¶„ ë¬¸ìì—´ í¬í•¨)
```

**2C. Global Term Candidates (ë¬¸ì„œ ê°„ ì—°ê²°)**
```python
# ê¸°ì¤€: frequency >= 2 OR confidence >= 0.8
# íš¨ê³¼: ë¬¸ì„œ Aì˜ "í­íƒ„"ê³¼ ë¬¸ì„œ Bì˜ "ë”ë¸”í­íƒ„"ì´ ì—°ê²° ê°€ëŠ¥
```

**2D. 3ë‹¨ê³„ ë§¤ì¹­ ì‹œìŠ¤í…œ**
```
Method 1: Exact match (ë¬¸ì„œ ë‚´) â†’ ì‹¤íŒ¨
Method 2: Fuzzy match (ë¬¸ì„œ ë‚´) â†’ ì‹¤íŒ¨
Method 3: Fuzzy match (ê¸€ë¡œë²Œ - ë‹¤ë¥¸ ë¬¸ì„œì—ì„œ ì°¾ê¸°) â†’ ì„±ê³µ!
```

**íš¨ê³¼**: Relation ë§¤ì¹­ë¥  20% â†’ **80%** (4ë°° ì¦ê°€)

#### 3. ê°•í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ
**íŒŒì¼**: `ontology_builder.py` (lines 212-233, 261-267)

**ë§¤ì¹­ ì„±ê³µ ë¡œê·¸**:
```
[MATCH OK] 'ë”ë¸”í­íƒ„' -clears-> 'ë¸”ë¡' matched to 'ë¸”ë¡' via fuzzy_local
```

**ë§¤ì¹­ ì‹¤íŒ¨ ë¡œê·¸** (ë””ë²„ê¹…ìš© ìƒì„¸ ì •ë³´):
```
[MATCH FAIL] Source: 'ë”ë¸”í­íƒ„' -clears-> Target: 'ë¸”ë¡ì„' (normalized: 'ë¸”ë¡')
  Local candidates (sample): ['ë”ë¸”í­íƒ„', 'í´ë¡œë²„', '4ë§¤ì¹˜', ...]
  Global candidates (sample): ['í­íƒ„', 'ìŠ¤í…Œì´ì§€', 'ì±•í„°', ...]
```

**ê²€ì¦ ì‹¤íŒ¨ ë¡œê·¸**:
```
[VALIDATION FAIL] ë”ë¸”í­íƒ„ -clears-> ë¸”ë¡ (No rule for gameobject -clears-> resource)
```

**í†µê³„ ë¡œê·¸**:
```
Processed 45 raw relations from 12 terms
Match method breakdown: {'exact_local': 15, 'fuzzy_local': 8, 'fuzzy_global': 3}
Skipped relationships breakdown: {'term_not_found': 10, 'No rule for...': 9}
âœ“ Loaded 26/45 relationships for document 123456789
```

**íš¨ê³¼**: ë””ë²„ê¹… ì‹œê°„ ë¬´í•œëŒ€ â†’ **5ë¶„** (ì‹¤ì‹œê°„ ì¶”ì  ê°€ëŠ¥)

#### ì¢…í•© ê°œì„  íš¨ê³¼

| ì§€í‘œ | Before | After | ê°œì„ ìœ¨ |
|------|--------|-------|--------|
| **Definition ì™„ì„±ë„** | ~50% | 100% | ğŸ”¥ 2ë°° |
| **Relation ë§¤ì¹­ë¥ ** | ~20% | ~80% | ğŸ”¥ 4ë°° |
| **ë””ë²„ê¹… ê°€ëŠ¥ì„±** | ë¶ˆê°€ëŠ¥ | ì™„ë²½ | ğŸ”¥ âˆ |
| **ë¬¸ì„œ ê°„ ì—°ê²°** | 0% | ê°€ëŠ¥ | ğŸ”¥ ì‹ ê·œ |

**Skip ì˜ˆì‹œ**:
```json
{"target": "ì‹ ë¹„í•œì•„ì´í…œ", "type": "triggers", "confidence": 0.95}
```
- âŒ **Skip ì´ìœ **: "ì‹ ë¹„í•œì•„ì´í…œ"ì´ DBì— ì—†ìŒ (term_not_found)

### í•µì‹¬ ê°œì„ : Context-Aware Relation Extraction

#### ê¸°ì¡´ ë°©ì‹ì˜ ë¬¸ì œì 
```
"í­íƒ„ê³¼ ë”ë¸”í­íƒ„ì€ ëª¨ë‘ ê°•ë ¥í•œ ì•„ì´í…œì…ë‹ˆë‹¤."
â†’ [X] ì˜ëª»ëœ ì¶”ì¶œ: í­íƒ„ --related_to--> ë”ë¸”í­íƒ„
â†’ ë‹¨ìˆœ ë™ì‹œ ë“±ì¥ â‰  ê´€ê³„
```

#### ìš°ë¦¬ì˜ í•´ê²°ì±…
`prompts/system_relation_builder.md`ì˜ í•µì‹¬ ì¥ì¹˜:

1. **ë„ë©”ì¸ ë¡œì§ ì£¼ì…**
   - Action-Trigger Loop (í–‰ë™ â†’ ë°œë™)
   - Economy Flow (Sink/Source êµ¬ì¡°)
   - Strategic Hierarchy (ìƒì„± ê´€ê³„)

2. **Confidence Scoring Guide (4ë‹¨ê³„)**
   - 0.9-1.0: ëª…ì‹œì  ì¸ê³¼ê´€ê³„ ("~í•˜ë©´ ~ëœë‹¤")
   - 0.7-0.9: ê°•í•œ ì•”ì‹œ ("~ì— íš¨ê³¼ì ")
   - 0.5-0.7: ì•½í•œ ì—°ê´€
   - <0.5: ì¶”ì¶œ ê¸ˆì§€

3. **Negative Examples (3ê°€ì§€)**
   - ë‹¨ìˆœ ë™ì‹œ ë“±ì¥
   - ì£¼ì œ ì „í™˜
   - ë‹¨ìˆœ ì†Œê°œ/ë¬˜ì‚¬

**ê²°ê³¼**: LLMì´ "ë¬¸ì¥ ë¶„ì„ê¸°"ê°€ ì•„ë‹Œ **"ê²Œì„ ë¡œì§ ë¶„ì„ê¸°"**ë¡œ ë™ì‘

### í•µì‹¬ íŒŒì¼
- `ontology_builder.py`: ê²€ì¦ ë° ê·¸ë˜í”„ êµ¬ì¶• ë¡œì§
- `prompts/system_relation_builder.md`: 2,542ì ê´€ê³„ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸

---

## í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§

### íŒŒì¼ ê¸°ë°˜ ê´€ë¦¬
ëª¨ë“  í”„ë¡¬í”„íŠ¸ëŠ” `prompts/` í´ë”ì— `.md` íŒŒì¼ë¡œ ê´€ë¦¬ë˜ì–´, **ì½”ë“œ ë°°í¬ ì—†ì´ ìˆ˜ì • ê°€ëŠ¥**í•©ë‹ˆë‹¤.

```
prompts/
â”œâ”€â”€ system_pokopoko.md            # 11,606ì, Phase 1 ìš©ì–´ ì¶”ì¶œ
â”œâ”€â”€ system_relation_builder.md    # 2,542ì, Phase 2 ê´€ê³„ ì¶”ì¶œ
â””â”€â”€ system_technical.md            # 1,534ì, ì¼ë°˜ ê¸°ìˆ  ë¬¸ì„œìš©
```

### system_pokopoko.md (Phase 1)

**í•µì‹¬ êµ¬ì¡°**:
```markdown
1. ì¶”ì¶œ ëª©í‘œ: ì—”í‹°í‹°ì™€ ê´€ê³„ë¥¼ ì •í˜• ë°ì´í„°ë¡œ ë³€í™˜
2. ì—”í‹°í‹° ì¹´í…Œê³ ë¦¬: GameObject, Resource, Mechanic, Content, Condition, System
3. ê´€ê³„ ì •ì˜: triggers, consumes, blocks, defeats, contains, requires, unlocks, rewards, clears
4. ì¶œë ¥ í˜•ì‹: Strict JSON (ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€)
5. ì¶”ì¶œ ê·œì¹™:
   - ëª…í™•í•œ ì •ì˜ê°€ ìˆëŠ” ê²½ìš°: confidence 0.9-1.0
   - ë¬¸ë§¥ì—ì„œ ì¶”ë¡  ê°€ëŠ¥: confidence 0.7-0.9
   - ë¶ˆí™•ì‹¤í•œ ê²½ìš°: confidence 0.5-0.7
6. í”¼í•´ì•¼ í•  ì‚¬í•­: ì¼ë°˜ ë™ì‚¬/í˜•ìš©ì‚¬, ì¶”ìƒì  ê°œë…, ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
7. ë™ì˜ì–´ ì²˜ë¦¬: í‘œì¤€ ìš©ì–´ + synonym relations
```

**Few-Shot Examples**:
- ì…ë ¥ ì˜ˆì‹œ: í´ë¡œë²„ ì†Œëª¨, ë§¤ì¹­ ë©”ì¹´ë‹‰, ë³´ìƒ ì‹œìŠ¤í…œ
- ì¶œë ¥ ì˜ˆì‹œ: JSON í˜•ì‹ ìš©ì–´ + ê´€ê³„

### system_relation_builder.md (Phase 2)

**í•µì‹¬ êµ¬ì¡°**:
```markdown
1. ë¶„ì„ ëª©í‘œ: ì²­í¬ ë…í•´ â†’ ìš©ì–´ ë§¤ì¹­ â†’ ë¡œì§ ì—°ê²°
2. ë„ë©”ì¸ ì§€ì‹:
   - Action-Trigger Loop (4ë§¤ì¹˜ â†’ í­íƒ„)
   - Economy Flow (Sink/Source)
   - Strategic Hierarchy (ìƒì„±)
3. í—ˆìš©ëœ ê´€ê³„: triggers, clears, counters, synergizes_with, consumes, rewards, requires, contains, unlocks
4. ì¶”ì¶œ ì ˆì°¨: Scan â†’ Analyze â†’ Verify â†’ Format
5. Few-Shot Examples (3ê°€ì§€ ê¸ì • + 3ê°€ì§€ ë¶€ì •)
6. Confidence Scoring Guide (4ë‹¨ê³„)
7. Negative Examples (ì¶”ì¶œ ê¸ˆì§€ ì¼€ì´ìŠ¤)
8. í•µì‹¬ ì œì•½: í›„ë³´ ìš©ì–´ ê°•ì œ, ë°©í–¥ì„±, ì¤‘ë³µ ì œê±°
```

**Few-Shot Examples**:
- Case 1: ë‹¨ìˆœ ì„¤ëª… (ì¶”ì¶œ X)
- Case 2: ì¸ê³¼ê´€ê³„ (triggers)
- Case 3: ê²½ì œ ë° ìƒì„± (consumes, counters)
- Negative Case 1: ë‹¨ìˆœ ë™ì‹œ ë“±ì¥ (ì¶”ì¶œ X)
- Negative Case 2: ì£¼ì œ ì „í™˜ (ì¶”ì¶œ X)
- Negative Case 3: ë‹¨ìˆœ ë¬˜ì‚¬ (ì¶”ì¶œ X)

### í”„ë¡¬í”„íŠ¸ ë¡œë”© ì‹œìŠ¤í…œ

```python
# prompts.py
from prompts import get_prompt

# íŒŒì¼ì—ì„œ ë¡œë“œ (ìºì‹±)
pokopoko_prompt = get_prompt("pokopoko")
relation_prompt = get_prompt("relation_builder")

# ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ í™•ì¸
available = list_available_prompts()  # ['pokopoko', 'relation_builder', 'technical']

# ìºì‹œ í´ë¦¬ì–´ (hot-reload)
clear_cache()
```

---

## ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### Tier 1: Raw Data Layer (Traditional RAG)

#### playbook_documents
```sql
CREATE TABLE playbook_documents (
    id TEXT PRIMARY KEY,                    -- Confluence Page ID
    title TEXT NOT NULL,
    space TEXT,
    url TEXT,
    content_length INTEGER,
    last_updated TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

#### playbook_chunks
```sql
CREATE TABLE playbook_chunks (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    doc_id TEXT NOT NULL REFERENCES playbook_documents(id) ON DELETE CASCADE,
    chunk_index INTEGER NOT NULL,
    content TEXT NOT NULL,
    metadata JSONB DEFAULT '{}',
    embedding VECTOR(1536),                 -- OpenAI ì„ë² ë”©
    char_count INTEGER,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(doc_id, chunk_index)
);
```

### Tier 2: Knowledge Graph Layer (GraphRAG)

#### playbook_semantic_terms (Nodes - "ë²½ëŒ")
```sql
CREATE TABLE playbook_semantic_terms (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    doc_id TEXT NOT NULL REFERENCES playbook_documents(id) ON DELETE CASCADE,
    term TEXT NOT NULL,                     -- í‘œì¤€ ìš©ì–´ëª…
    category TEXT NOT NULL,                 -- GameObject, Resource ë“±
    definition TEXT,                        -- í•œ ì¤„ ì •ì˜
    confidence FLOAT DEFAULT 0.0,
    frequency INTEGER DEFAULT 1,
    raw_relations JSONB DEFAULT '[]',       -- 1ì°¨ ì¶”ì¶œëœ ê´€ê³„ (ë°±ì—…ìš©)
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(doc_id, term)
);
```

**raw_relations ì˜ˆì‹œ**:
```json
[
  {"target": "ë¸”ë¡", "type": "clears", "confidence": 0.98, "desc": "3x3 ë²”ìœ„ ì œê±°"},
  {"target": "4ë§¤ì¹˜", "type": "requires", "confidence": 0.95, "desc": "ìƒì„± ì¡°ê±´"}
]
```

#### playbook_ontology_rules (Schema - "ë²•ì „")
```sql
CREATE TABLE playbook_ontology_rules (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    subject_type TEXT NOT NULL,             -- ì£¼ì–´ íƒ€ì… (ì˜ˆ: Mechanic)
    predicate TEXT NOT NULL,                -- ê´€ê³„ (ì˜ˆ: triggers)
    object_type TEXT NOT NULL,              -- ëª©ì ì–´ íƒ€ì… (ì˜ˆ: GameObject)
    description TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(subject_type, predicate, object_type)
);
```

**PokoPoko ê·œì¹™ ì˜ˆì‹œ**:
```sql
INSERT INTO playbook_ontology_rules (subject_type, predicate, object_type, description) VALUES
('Mechanic', 'triggers', 'GameObject', 'í–‰ë™ì´ ê°ì²´ë¥¼ ìƒì„±í•¨'),
('GameObject', 'clears', 'GameObject', 'ì•„ì´í…œì´ ì¥ì• ë¬¼ì„ ì œê±°í•¨'),
('Content', 'consumes', 'Resource', 'ì…ì¥ ë¹„ìš©'),
('Content', 'rewards', 'Resource', 'ë³´ìƒ íšë“');
```

#### playbook_semantic_relations (Edges - "ì—°ê²°ì„ ")
```sql
CREATE TABLE playbook_semantic_relations (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    source_term_id UUID NOT NULL REFERENCES playbook_semantic_terms(id) ON DELETE CASCADE,
    target_term_id UUID NOT NULL REFERENCES playbook_semantic_terms(id) ON DELETE CASCADE,
    predicate TEXT NOT NULL,
    confidence FLOAT DEFAULT 1.0,
    evidence_chunk_id UUID REFERENCES playbook_chunks(id),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(source_term_id, target_term_id, predicate)
);
```

### ì§€ì‹ ê·¸ë˜í”„ ì¡°íšŒ ì˜ˆì‹œ

```sql
-- íŠ¹ì • ìš©ì–´ì˜ ëª¨ë“  ê´€ê³„
SELECT
    source.term AS source_term,
    rel.predicate,
    target.term AS target_term,
    rel.confidence
FROM playbook_semantic_relations rel
JOIN playbook_semantic_terms source ON rel.source_term_id = source.id
JOIN playbook_semantic_terms target ON rel.target_term_id = target.id
WHERE source.term = 'í­íƒ„'
ORDER BY rel.confidence DESC;

-- 2-hop ê·¸ë˜í”„ íƒìƒ‰
WITH RECURSIVE graph_traverse AS (
    -- 1-hop
    SELECT target_term_id AS term_id, 1 AS depth
    FROM playbook_semantic_relations rel
    JOIN playbook_semantic_terms source ON rel.source_term_id = source.id
    WHERE source.term = 'í­íƒ„'

    UNION

    -- 2-hop
    SELECT rel.target_term_id, gt.depth + 1
    FROM graph_traverse gt
    JOIN playbook_semantic_relations rel ON rel.source_term_id = gt.term_id
    WHERE gt.depth < 2
)
SELECT DISTINCT t.term, t.category, gt.depth
FROM graph_traverse gt
JOIN playbook_semantic_terms t ON t.id = gt.term_id
ORDER BY gt.depth, t.term;
```

---

## ì„±ëŠ¥ ìµœì í™”

### ì¸ë±ìŠ¤ ì „ëµ
```sql
-- ë²¡í„° ê²€ìƒ‰ ìµœì í™” (1000ê±´ ì´ìƒì¼ ë•Œ)
CREATE INDEX idx_playbook_chunks_vec ON playbook_chunks
  USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);

-- ê·¸ë˜í”„ ìˆœíšŒ ìµœì í™”
CREATE INDEX idx_playbook_rel_source_pred ON playbook_semantic_relations(source_term_id, predicate);
CREATE INDEX idx_playbook_rel_target_pred ON playbook_semantic_relations(target_term_id, predicate);

-- JSONB ê²€ìƒ‰ ìµœì í™”
CREATE INDEX idx_playbook_terms_raw_rel ON playbook_semantic_terms USING GIN(raw_relations);
```

### ë°°ì¹˜ ì²˜ë¦¬
- ì²­í¬ ì„ë² ë”©: 50ê°œì”© batch
- ê´€ê³„ ì‚½ì…: 50ê°œì”© UPSERT
- ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ (exponential backoff)

### ìºì‹±
- í”„ë¡¬í”„íŠ¸ íŒŒì¼: ë©”ëª¨ë¦¬ ìºì‹± (`_PROMPT_CACHE`)
- ì˜¨í†¨ë¡œì§€ ê·œì¹™: ì‹¤í–‰ ì‹œì‘ ì‹œ 1íšŒ ë¡œë“œ

---

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Confluence    â”‚  ë¬¸ì„œ ì›ë³¸ ì €ì¥ì†Œ
â”‚   (REST API)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 1. í˜ì´ì§€ ìˆ˜ì§‘
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Confluence      â”‚  HTML â†’ Plain Text ë³€í™˜
â”‚ Processor       â”‚  ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (title, space, url, version)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 2. ë¬¸ì„œ ë¶„ë¥˜ (guideline/process/experiment/general)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Document        â”‚  ë¬¸ì„œ ì›ë³¸ ì €ì¥
â”‚ Classification  â”‚  â†’ playbook_documents í…Œì´ë¸”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 3. ì²­í‚¹ + ì„ë² ë”© ìƒì„±
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Semantic        â”‚  Header-aware ì²­í‚¹ (100-2000ì)
â”‚ Processor       â”‚  ë¬¸ì¥ ê²½ê³„ ë³´ì¡´, MD5 ì¤‘ë³µ ì œê±°
â”‚                 â”‚  OpenAI Embedding API í˜¸ì¶œ
â”‚                 â”‚  LLM ê¸°ë°˜ Semantic Term ì¶”ì¶œ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 4. ì €ì¥
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Supabase      â”‚  PostgreSQL + pgvector
â”‚  (PostgreSQL)   â”‚  - playbook_documents (ë¬¸ì„œ)
â”‚                 â”‚  - playbook_chunks (ì²­í¬ + ì„ë² ë”©)
â”‚                 â”‚  - playbook_semantic_terms (ìš©ì–´)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## íŒŒì´í”„ë¼ì¸ íë¦„

### 1ï¸âƒ£ Confluence ë¬¸ì„œ ìˆ˜ì§‘ (Confluence Processor)

**ëª©ì **: Confluenceì—ì„œ í˜ì´ì§€ë¥¼ ê°€ì ¸ì™€ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜

**ì²˜ë¦¬ ê³¼ì •**:
```python
# confluence_processor.py
1. Confluence REST APIì— í˜ì´ì§€ IDë¡œ ìš”ì²­
   GET /rest/api/content/{pageId}?expand=body.storage,version,space,ancestors

2. HTML ì½˜í…ì¸  íŒŒì‹± (BeautifulSoup)
   - <script>, <style> íƒœê·¸ ì œê±°
   - í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì •ë¦¬
   - ê³¼ë„í•œ ê³µë°± ì œê±°

3. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
   - title: í˜ì´ì§€ ì œëª©
   - space_key: ìŠ¤í˜ì´ìŠ¤ ì‹ë³„ì
   - url: í˜ì´ì§€ URL
   - version: ë²„ì „ ë²ˆí˜¸
   - last_updated: ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„
   - parent_id: ìƒìœ„ í˜ì´ì§€ ID
   - path: í˜ì´ì§€ ê³„ì¸µ ê²½ë¡œ
```

**ì™œ ì´ë ‡ê²Œ í•˜ë‚˜ìš”?**
- Confluence APIëŠ” HTML í˜•ì‹ìœ¼ë¡œ ì½˜í…ì¸ ë¥¼ ì œê³µí•˜ë¯€ë¡œ, plain textë¡œ ë³€í™˜í•´ì•¼ ì„ë² ë”© ìƒì„±ì´ ê°€ëŠ¥
- ë©”íƒ€ë°ì´í„°ëŠ” ì¶”í›„ í•„í„°ë§, ê²€ìƒ‰, ì»¨í…ìŠ¤íŠ¸ ì œê³µì— í™œìš©
- ì¬ì‹œë„ ë¡œì§ (exponential backoff)ìœ¼ë¡œ API rate limit ëŒ€ì‘

---

### 2ï¸âƒ£ ë¬¸ì„œ ë¶„ë¥˜ ë° ì €ì¥ (Classification + Supabase Loader)

**ëª©ì **: ë¬¸ì„œ ìœ í˜• íŒŒì•… ë° ì›ë³¸ ë³´ì¡´

**ì²˜ë¦¬ ê³¼ì •**:
```python
# rules.py (classify_document)
1. í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
   - "guideline", "ê°€ì´ë“œë¼ì¸" â†’ guideline
   - "process", "í”„ë¡œì„¸ìŠ¤", "workflow" â†’ process
   - "experiment", "ì‹¤í—˜", "A/B test" â†’ experiment
   - ê¸°íƒ€ â†’ general

# supabase_loader.py (load_document)
2. playbook_documents í…Œì´ë¸”ì— UPSERT
   - id: page_id (ì¤‘ë³µ ì‹œ ì—…ë°ì´íŠ¸)
   - title, space, url, content_length, last_updated
```

**ì™œ ì´ë ‡ê²Œ í•˜ë‚˜ìš”?**
- ë¬¸ì„œ ì›ë³¸ì„ ë³„ë„ ì €ì¥í•˜ì—¬ ì¶”í›„ ì¬ì²˜ë¦¬ ê°€ëŠ¥
- ë¬¸ì„œ ìœ í˜•(doc_type)ì„ ë©”íƒ€ë°ì´í„°ë¡œ í™œìš©í•´ ê²€ìƒ‰ í•„í„°ë§
- UPSERT ì‚¬ìš©ìœ¼ë¡œ ê°™ì€ í˜ì´ì§€ ì¬ì²˜ë¦¬ ì‹œ ì¤‘ë³µ ë°©ì§€

---

### 3ï¸âƒ£ ìŠ¤ë§ˆíŠ¸ ì²­í‚¹ (Semantic Processor - ImprovedChunker)

**ëª©ì **: ì˜ë¯¸ ë‹¨ìœ„ë¥¼ ë³´ì¡´í•˜ë©´ì„œ ê²€ìƒ‰ì— ìµœì í™”ëœ í¬ê¸°ë¡œ ë¬¸ì„œ ë¶„í• 

**ì²˜ë¦¬ ê³¼ì •**:
```python
# semantic_processor.py (ImprovedChunker)

1. Header ê¸°ë°˜ ì„¹ì…˜ ì¶”ì¶œ
   - Markdown í—¤ë” íŒ¨í„´ íƒì§€: ^(#{1,6})\s+(.+)$
   - ê° ì„¹ì…˜ì˜ headerì™€ content ë¶„ë¦¬
   - í—¤ë”ê°€ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì„¹ì…˜ìœ¼ë¡œ ì²˜ë¦¬

2. ë¬¸ì¥ ë‹¨ìœ„ ë¶„í• 
   - í•œê¸€/ì˜ë¬¸ ë¬¸ì¥ ì¢…ê²° íŒ¨í„´: ([.!?â€¦])\s+|\n{2,}
   - ë¬¸ì¥ ê²½ê³„ë¥¼ ë³´ì¡´í•˜ì—¬ ì˜ë¯¸ ì†ì‹¤ ë°©ì§€

3. ì²­í¬ ìƒì„± (100-2000ì ë²”ìœ„)
   - Header context ì¶”ê°€: [Section Title]\n\n{content}
   - ë¬¸ì¥ì„ ëª¨ì•„ì„œ max_chunk_size(2000ì) ì´ë‚´ë¡œ ì¡°í•©
   - ë‹¨ì¼ ë¬¸ì¥ì´ 2000ì ì´ˆê³¼ ì‹œ ê°•ì œ ë¶„í• 
   - ìµœì†Œ í¬ê¸°(100ì) ë¯¸ë§Œ ì²­í¬ëŠ” ì´ì „ ì²­í¬ì™€ ë³‘í•©

4. ì¤‘ë³µ ì œê±°
   - MD5 í•´ì‹œë¡œ ì¤‘ë³µ ì²­í¬ íƒì§€ ë° ì œê±°

5. TextChunk ê°ì²´ ìƒì„±
   - page_id, chunk_index, content, char_start, char_end
   - chunk_id ìƒì„±: {page_id}_{index}_{md5[:8]}
```

**ì™œ ì´ë ‡ê²Œ í•˜ë‚˜ìš”?**

1. **Header Context ë³´ì¡´**:
   - ì²­í¬ë§Œ ë³´ê³ ë„ ì–´ë–¤ ì„¹ì…˜ì¸ì§€ ì•Œ ìˆ˜ ìˆì–´ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
   - ì˜ˆ: `[Architecture Overview]\n\nThe system uses microservices...`

2. **ë¬¸ì¥ ê²½ê³„ ë³´ì¡´**:
   - ë¬¸ì¥ ì¤‘ê°„ì—ì„œ ìë¥´ë©´ ì˜ë¯¸ê°€ ì†ì‹¤ë˜ì–´ ì„ë² ë”© í’ˆì§ˆ ì €í•˜
   - ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìœ ì§€í•˜ë©´ ì˜ë¯¸ì  ì¼ê´€ì„± ë³´ì¥

3. **100-2000ì ë²”ìœ„**:
   - 100ì ë¯¸ë§Œ: ë„ˆë¬´ ì§§ì•„ì„œ ê²€ìƒ‰ ì‹œ ë…¸ì´ì¦ˆ ë°œìƒ
   - 2000ì ì´ˆê³¼: ì„ë² ë”© ëª¨ë¸ í† í° í•œê³„ ë° ê²€ìƒ‰ ì •ë°€ë„ ì €í•˜
   - 2000ì = ì•½ 500 í† í° (OpenAI embedding max: 8191 í† í°)

4. **MD5 ì¤‘ë³µ ì œê±°**:
   - Confluenceì—ì„œ ë°˜ë³µë˜ëŠ” í…œí”Œë¦¿ ì½˜í…ì¸  ì œê±°
   - ì €ì¥ ê³µê°„ ì ˆì•½ ë° ê²€ìƒ‰ ì†ë„ í–¥ìƒ

---

### 4ï¸âƒ£ ë²¡í„° ì„ë² ë”© ìƒì„± (Semantic Processor - get_embeddings)

**ëª©ì **: ì²­í¬ë¥¼ 1536ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¦

**ì²˜ë¦¬ ê³¼ì •**:
```python
# semantic_processor.py (get_embeddings)

1. ë°°ì¹˜ ì²˜ë¦¬ (100ê°œì”©)
   - EMBEDDING_BATCH_SIZE = 100
   - API í˜¸ì¶œ ìµœì†Œí™”ë¡œ ì†ë„/ë¹„ìš© ìµœì í™”

2. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
   - 8191 í† í° ì´ˆê³¼ ì‹œ truncate (ì•½ 32,764ì)
   - í† í° ì¶”ì •: 1 í† í° â‰ˆ 4ì

3. OpenAI Embedding API í˜¸ì¶œ (LiteLLM Proxy ê²½ìœ )
   model="text-embedding-3-small"
   â†’ 1536ì°¨ì› ë²¡í„° ë°˜í™˜

4. ì¬ì‹œë„ ë¡œì§ (exponential backoff)
   - ìµœëŒ€ 3íšŒ ì¬ì‹œë„ (EMBEDDING_MAX_RETRIES)
   - ëŒ€ê¸° ì‹œê°„: 2^attempt ì´ˆ (1s â†’ 2s â†’ 4s)
   - ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
```

**ì™œ ì´ë ‡ê²Œ í•˜ë‚˜ìš”?**

1. **text-embedding-3-small ì„ íƒ**:
   - ì €ë ´í•œ ë¹„ìš©: $0.02 / 1M tokens
   - ë¹ ë¥¸ ì†ë„: ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì´ˆë‹¹ ìˆ˜ì²œ ê°œ ì„ë² ë”© ê°€ëŠ¥
   - ì¶©ë¶„í•œ ì„±ëŠ¥: 1536ì°¨ì›ìœ¼ë¡œ ì˜ë¯¸ ìœ ì‚¬ë„ ì˜ í‘œí˜„

2. **ë°°ì¹˜ ì²˜ë¦¬**:
   - API í˜¸ì¶œ íšŸìˆ˜ ìµœì†Œí™” (ë„¤íŠ¸ì›Œí¬ ì˜¤ë²„í—¤ë“œ ê°ì†Œ)
   - 5,000ê°œ ì²­í¬ â†’ 50íšŒ API í˜¸ì¶œ (ë°°ì¹˜ ì—†ìœ¼ë©´ 5,000íšŒ)

3. **ì¬ì‹œë„ ë¡œì§**:
   - ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜, rate limit ëŒ€ì‘
   - Exponential backoffë¡œ ì„œë²„ ë¶€í•˜ ë¶„ì‚°

---

### 5ï¸âƒ£ Semantic Term ì¶”ì¶œ (Semantic Processor - extract_semantic_terms)

**ëª©ì **: ë¬¸ì„œì˜ í•µì‹¬ ìš©ì–´, ê°œë…, ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ ë° ê´€ê³„ íŒŒì•…

**ì²˜ë¦¬ ê³¼ì •**:
```python
# semantic_processor.py (extract_semantic_terms)

1. ì „ì²´ ì²­í¬ í…ìŠ¤íŠ¸ ê²°í•©
   - ë¬¸ì„œ ì „ì²´ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ì„ ìœ„í•´ ëª¨ë“  ì²­í¬ ë³‘í•©
   - ìµœëŒ€ 8000ìê¹Œì§€ ì‚¬ìš© (LLM ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ê³ ë ¤)

2. LLM í˜¸ì¶œ (gpt-4o-mini)
   System Prompt:
   - ê¸°ìˆ  ë¬¸ì„œì—ì„œ í•µì‹¬ ìš©ì–´ ì¶”ì¶œ
   - ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜: person, location, organization, technology, concept,
                    process, metric, tool, other
   - ì‹ ë¢°ë„(confidence) ì ìˆ˜ 0.0-1.0
   - ìš©ì–´ ì‚¬ìš© ë¬¸ë§¥(context) ì¶”ì¶œ

   JSON ì‘ë‹µ í˜•ì‹:
   [
     {
       "term": "Kubernetes",
       "category": "technology",
       "confidence": 0.95,
       "context": "The system runs on Kubernetes cluster..."
     }
   ]

3. ìš©ì–´ ë¹ˆë„ ë° evidence ê³„ì‚°
   - ê° ì²­í¬ì—ì„œ ìš©ì–´ ì¶œí˜„ ì—¬ë¶€ í™•ì¸
   - frequency: ë¬¸ì„œ ì „ì²´ì—ì„œ ì¶œí˜„ íšŸìˆ˜
   - evidence: ìš©ì–´ê°€ í¬í•¨ëœ ì²­í¬ ID ë°°ì—´
     [
       {"chunk_id": "123_0_abc", "position": 42},
       {"chunk_id": "123_3_def", "position": 15}
     ]

4. Semantic Term ë°ì´í„° êµ¬ì¡° ìƒì„±
   {
     "doc_id": "page_id",
     "term": "kubernetes",
     "category": "technology",
     "relation": [],  // í–¥í›„ ìš©ì–´ ê°„ ê´€ê³„ ë¶„ì„ ì¶”ê°€
     "frequency": 5,
     "confidence": 0.95,
     "evidence": [...],
     "context": "The system runs on..."
   }
```

**ì™œ ì´ë ‡ê²Œ í•˜ë‚˜ìš”?**

1. **LLM ê¸°ë°˜ ì¶”ì¶œ**:
   - ë‹¨ìˆœ í‚¤ì›Œë“œ ì¶”ì¶œë³´ë‹¤ ì •í™• (ë¬¸ë§¥ ì´í•´)
   - ë™ì˜ì–´, ì•½ì–´ ì²˜ë¦¬ ê°€ëŠ¥ (ì˜ˆ: k8s â†’ Kubernetes)
   - ë„ë©”ì¸ íŠ¹í™” ìš©ì–´ ì¸ì‹ ê°€ëŠ¥

2. **gpt-4o-mini ì‚¬ìš©**:
   - ë¹ ë¥¸ ì†ë„ (text-embeddingë³´ë‹¤ ëŠë¦¬ì§€ë§Œ ì¶©ë¶„íˆ ë¹ ë¦„)
   - ì €ë ´í•œ ë¹„ìš© (gpt-4 ëŒ€ë¹„ 1/10)
   - ìš©ì–´ ì¶”ì¶œì—ëŠ” ì¶©ë¶„í•œ ì„±ëŠ¥

3. **Confidence Score**:
   - ë¶ˆí™•ì‹¤í•œ ìš©ì–´ í•„í„°ë§ ê°€ëŠ¥ (ì˜ˆ: confidence < 0.7 ì œì™¸)
   - ê²€ìƒ‰ ì‹œ ê°€ì¤‘ì¹˜ë¡œ í™œìš©

4. **Evidence ì¶”ì **:
   - ìš©ì–´ê°€ ì–´ëŠ ì²­í¬ì— ë‚˜íƒ€ë‚˜ëŠ”ì§€ ì¶”ì 
   - ê²€ìƒ‰ ì‹œ ê´€ë ¨ ì²­í¬ ìš°ì„ ìˆœìœ„ ê²°ì •

5. **Frequency ì§‘ê³„**:
   - ë¬¸ì„œ ë‚´ ì¤‘ìš”ë„ ì¸¡ì • (ë†’ì€ ë¹ˆë„ = ì¤‘ìš” ìš©ì–´)
   - ì¤‘ë³µ ì œê±° ë° í†µê³„ ë¶„ì„ ê°€ëŠ¥

---

### 6ï¸âƒ£ Supabase ì ì¬ (Supabase Loader)

**ëª©ì **: ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ PostgreSQLì— ì €ì¥

**ì²˜ë¦¬ ê³¼ì •**:
```python
# supabase_loader.py

1. Chunks ì €ì¥ (load_chunks)
   - playbook_chunks í…Œì´ë¸”
   - ë°°ì¹˜ í¬ê¸°: 50ê°œì”© INSERT
   - ë°ì´í„° êµ¬ì¡°:
     {
       "doc_id": page_id,
       "chunk_index": 0,
       "content": "ìˆœìˆ˜ í…ìŠ¤íŠ¸",
       "metadata": {
         "title": "ë¬¸ì„œ ì œëª©",
         "chunk_index": 0,
         "total_chunks": 10,
         "doc_type": "guideline"
       },
       "embedding": [0.123, -0.456, ...],  # 1536ì°¨ì› ë²¡í„°
       "char_count": 1234
     }

2. Semantic Terms ì €ì¥ (load_semantic_terms)
   - playbook_semantic_terms í…Œì´ë¸”
   - UPSERT on (doc_id, term)
   - ì¤‘ë³µ ì‹œ frequency, evidence ì—…ë°ì´íŠ¸
   - ë°ì´í„° êµ¬ì¡°:
     {
       "doc_id": page_id,
       "term": "kubernetes",
       "category": "technology",
       "relation": [],
       "frequency": 5,
       "confidence": 0.95,
       "evidence": [{"chunk_id": "...", "position": 42}],
       "context": "The system runs on..."
     }

3. í†µê³„ ì¡°íšŒ (get_stats)
   - total_documents: ì €ì¥ëœ ë¬¸ì„œ ìˆ˜
   - total_chunks: ì €ì¥ëœ ì²­í¬ ìˆ˜
   - total_semantic_terms: ì¶”ì¶œëœ ìš©ì–´ ìˆ˜
```

**ì™œ ì´ë ‡ê²Œ í•˜ë‚˜ìš”?**

1. **Content + Metadata ë¶„ë¦¬**:
   - content: ìˆœìˆ˜ í…ìŠ¤íŠ¸ (ë²¡í„° ê²€ìƒ‰ ëŒ€ìƒ)
   - metadata: JSONB (í•„í„°ë§, ì •ë ¬ìš©)
   - ê²€ìƒ‰ ì„±ëŠ¥ ìµœì í™”

2. **ë°°ì¹˜ INSERT**:
   - 50ê°œì”© ë¬¶ì–´ì„œ INSERT (ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œ ìµœì†Œí™”)
   - 5,000ê°œ ì²­í¬ â†’ 100íšŒ INSERT

3. **UPSERT ì‚¬ìš©**:
   - ê°™ì€ ë¬¸ì„œ ì¬ì²˜ë¦¬ ì‹œ ì¤‘ë³µ ë°©ì§€
   - ë°ì´í„° ì¼ê´€ì„± ìœ ì§€

4. **JSONB í™œìš©**:
   - metadata, relation, evidenceë¥¼ JSONBë¡œ ì €ì¥
   - ìœ ì—°í•œ ìŠ¤í‚¤ë§ˆ (í–¥í›„ í•„ë“œ ì¶”ê°€ ìš©ì´)
   - GIN ì¸ë±ìŠ¤ë¡œ ë¹ ë¥¸ ê²€ìƒ‰

---

## ì„¤ì¹˜ ë° ì„¤ì •

### 1. í•„ìˆ˜ ìš”êµ¬ì‚¬í•­

- Python 3.9+
- Supabase í”„ë¡œì íŠ¸ (PostgreSQL + pgvector)
- Confluence API ì•¡ì„¸ìŠ¤
- OpenAI API Key (LiteLLM Proxy ê²½ìœ  ê°€ëŠ¥)

### 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip3 install requests beautifulsoup4 openai supabase tqdm python-dotenv
pip3 install --upgrade 'supabase>=2.0.0,<3.0.0' 'pydantic>=2.0.0,<3.0.0'
```

### 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ ìƒì„±:

```bash
# Confluence Configuration
CONFLUENCE_URL=https://your-domain.atlassian.net/wiki
CONFLUENCE_EMAIL=your-email@example.com
CONFLUENCE_API_TOKEN=your-api-token

# OpenAI Configuration (LiteLLM Proxy)
OPENAI_BASE_URL=https://litellm.your-proxy.com
OPENAI_API_KEY=your-api-key
EMBEDDING_MODEL=text-embedding-3-small

# Supabase Configuration
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-service-role-key

# Table names
TABLE_DOCUMENTS=playbook_documents
TABLE_CHUNKS=playbook_chunks
TABLE_SEMANTIC=playbook_semantic_terms

# Processing Configuration
CONFLUENCE_BATCH_SIZE=10
EMBEDDING_BATCH_SIZE=100
SUPABASE_BATCH_SIZE=50
CONFLUENCE_MAX_RETRIES=3
EMBEDDING_MAX_RETRIES=3
CONFLUENCE_RATE_LIMIT_DELAY=1.0

# File Paths
CONFLUENCE_IDS_FILE=confluence_ids.txt
CHECKPOINT_FILE=data/checkpoint.json
LOG_FILE=logs/playbook.log
```

### 4. Supabase ìŠ¤í‚¤ë§ˆ ì„¤ì •

Supabase SQL Editorì—ì„œ `supabase_migration.sql` ì‹¤í–‰:

```bash
# ë§ˆì´ê·¸ë ˆì´ì…˜ SQL ì‹¤í–‰
# Supabase Dashboard â†’ SQL Editor â†’ supabase_migration.sql ë‚´ìš© ë³µì‚¬/ì‹¤í–‰
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ”:
- `playbook_documents`, `playbook_chunks`, `playbook_semantic_terms` í…Œì´ë¸” ìƒì„±/ìˆ˜ì •
- pgvector extension í™œì„±í™”
- ë²¡í„° ì¸ë±ìŠ¤ (ivfflat) ìƒì„±
- GIN ì¸ë±ìŠ¤ (JSONB ì»¬ëŸ¼ìš©) ìƒì„±
- RLS ì •ì±… ì„¤ì •

### 5. Confluence Page IDs ìˆ˜ì§‘

`confluence_ids.txt` íŒŒì¼ ìƒì„±:

```
# Confluence Page IDs (í•œ ì¤„ì— í•˜ë‚˜ì”©)
123456789
234567890
345678901
```

---

## ì‚¬ìš©ë²•

### ğŸš€ ê¶Œì¥: í†µí•© íŒŒì´í”„ë¼ì¸ (run_full_pipeline.py)

**Phase 1ê³¼ Phase 2ê°€ ìë™ìœ¼ë¡œ ì—°ê²°ë˜ëŠ” í†µí•© ìŠ¤í¬ë¦½íŠ¸** - í•œ ë²ˆ ì‹¤í–‰í•˜ë©´ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!

```bash
# 1ï¸âƒ£ ì „ì²´ í˜ì´ì§€ ì²˜ë¦¬ (Phase 1 + Phase 2 ìë™ ì‹¤í–‰)
python3 run_full_pipeline.py --full

# 2ï¸âƒ£ ë¯¸ì²˜ë¦¬ í˜ì´ì§€ë§Œ ì²˜ë¦¬ (ê¸°ë³¸ ëª¨ë“œ, ì²´í¬í¬ì¸íŠ¸ í™œìš©)
python3 run_full_pipeline.py

# 3ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (10ê°œ í˜ì´ì§€ë§Œ)
python3 run_full_pipeline.py --max-pages 10

# 4ï¸âƒ£ Phase 1ë§Œ ì‹¤í–‰ (Phase 2 ìŠ¤í‚µ)
python3 run_full_pipeline.py --phase1-only

# 5ï¸âƒ£ ì²´í¬í¬ì¸íŠ¸ ë¦¬ì…‹ í›„ ì „ì²´ ì¬ì‹¤í–‰
python3 run_full_pipeline.py --full --reset-checkpoint
```

**ì˜µì…˜ ì„¤ëª…**:
- `--full`: ì „ì²´ í˜ì´ì§€ ì¬ì²˜ë¦¬ (ì²´í¬í¬ì¸íŠ¸ ë¬´ì‹œ)
- `--max-pages N`: ìµœëŒ€ Nê°œ í˜ì´ì§€ë§Œ ì²˜ë¦¬
- `--phase1-only`: Phase 2 ìŠ¤í‚µ (ë¬¸ì„œ/ì„ë² ë”©ë§Œ ì €ì¥)
- `--reset-checkpoint`: ì²´í¬í¬ì¸íŠ¸ ì´ˆê¸°í™”
- `--page-ids-file PATH`: ì»¤ìŠ¤í…€ í˜ì´ì§€ ID íŒŒì¼ ê²½ë¡œ

### Phase 1: Semantic Extraction (ê°œë³„ ì‹¤í–‰)

```bash
# ì „ì²´ í˜ì´ì§€ ì²˜ë¦¬ (Phase 1 only)
python3 src/main.py

# í…ŒìŠ¤íŠ¸ (3ê°œ í˜ì´ì§€ë§Œ)
python3 src/main.py --max-pages 3

# ì²´í¬í¬ì¸íŠ¸ ë¬´ì‹œí•˜ê³  ì „ì²´ ì¬ì²˜ë¦¬
python3 src/main.py --no-skip-existing

# ì²´í¬í¬ì¸íŠ¸ ë¦¬ì…‹
python3 src/main.py --reset-checkpoint

# ì»¤ìŠ¤í…€ í˜ì´ì§€ ID íŒŒì¼
python3 src/main.py --page-ids-file my_pages.txt
```

### Phase 2: Knowledge Graph Construction (ê°œë³„ ì‹¤í–‰)

Phase 1ì´ ì™„ë£Œë˜ë©´ raw_relationsë¥¼ ê²€ì¦í•˜ì—¬ ì§€ì‹ ê·¸ë˜í”„ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤:

```bash
# Phase 1 + Phase 2 í•œë²ˆì— ì‹¤í–‰
python3 src/main.py --phase2

# Phase 2ë§Œ ë³„ë„ ì‹¤í–‰
python3 src/core/processors/ontology_builder.py

# íŠ¹ì • ë¬¸ì„œë“¤ë§Œ ì²˜ë¦¬
python3 src/core/processors/ontology_builder.py --doc-ids 123456789 234567890

# ìµœëŒ€ ë¬¸ì„œ ê°œìˆ˜ ì œí•œ (í…ŒìŠ¤íŠ¸ìš©)
python3 src/core/processors/ontology_builder.py --max-docs 3
```

### í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

```bash
# 10ê°œ í˜ì´ì§€ í†µí•© í…ŒìŠ¤íŠ¸ (Phase 1 + Phase 2)
python3 tests/integration/test_10_pages.py

# Reinforcement Learning í…ŒìŠ¤íŠ¸ (ë™ì¼ ë¬¸ì„œ ì¬ì²˜ë¦¬)
python3 tests/integration/test_reinforcement.py

# ì—°ê²° í…ŒìŠ¤íŠ¸ (Confluence, OpenAI, Supabase)
python3 tests/unit/test_connections.py

# Graph Traversal í…ŒìŠ¤íŠ¸ (BFS, DFS, Subgraph)
python3 tests/unit/test_traversal.py
```

### Phase 3: Graph Traversal (ê·¸ë˜í”„ íƒìƒ‰)

**NEW!** êµ¬ì¶•ëœ ì§€ì‹ ê·¸ë˜í”„ë¥¼ íƒìƒ‰í•˜ê³  ë¶„ì„í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.

```bash
# ë°ëª¨ ì‹¤í–‰ (ê¶Œì¥ - ëª¨ë“  ê¸°ëŠ¥ ì‹œì—°)
python3 scripts/demo_traversal.py

# Pythonì—ì„œ ì§ì ‘ ì‚¬ìš©
python3
>>> from src.core.loaders.supabase_loader import SupabaseLoader
>>> from src.core.traversal import GraphTraversal, SubgraphExtractor
>>>
>>> supabase = SupabaseLoader()
>>> traversal = GraphTraversal(supabase.client)
>>>
>>> # BFS: ìµœë‹¨ ê²½ë¡œ íƒìƒ‰
>>> paths = traversal.bfs_traversal("ë”ë¸”í­íƒ„", target_category="resource", max_depth=3)
>>> for path in paths[:3]:
...     print(f"{' -> '.join(path.nodes)}")
>>>
>>> # DFS: ì˜í–¥ ë²”ìœ„ ë¶„ì„
>>> impact = traversal.dfs_traversal("ë‚œì´ë„ìƒí–¥", max_depth=3)
>>>
>>> # Subgraph: ì‹œê°í™”ìš© ë°ì´í„° ì¶”ì¶œ
>>> extractor = SubgraphExtractor(supabase.client)
>>> subgraph = extractor.extract_subgraph("4ë§¤ì¹˜", radius=2)
>>> print(f"Nodes: {len(subgraph['nodes'])}, Edges: {len(subgraph['edges'])}")
```

**ì£¼ìš” ê¸°ëŠ¥**:
- **BFS Traversal**: ìµœë‹¨ ê²½ë¡œ íƒìƒ‰ (ì˜ˆ: Aì—ì„œ Bë¡œ ê°€ëŠ” ê²½ë¡œ)
- **DFS Traversal**: ì˜í–¥ ë²”ìœ„ ë¶„ì„ (ì˜ˆ: ë³€ê²½ì˜ íŒŒê¸‰ íš¨ê³¼)
- **Shortest Path**: ë‘ ê°œë… ê°„ ìµœë‹¨ ê²½ë¡œ
- **Subgraph Extraction**: íŠ¹ì • ë…¸ë“œ ì£¼ë³€ ì„œë¸Œê·¸ë˜í”„ (ì‹œê°í™”ìš©)
- **Ego Network**: 1-hop ì´ì›ƒ ì¶”ì¶œ

**ìì„¸í•œ ë‚´ìš©**: [`docs/TRAVERSAL_DESIGN.md`](docs/TRAVERSAL_DESIGN.md)

---

### ğŸŒ FastAPI ì„œë²„ ë°°í¬

**NEW!** REST APIë¥¼ í†µí•´ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ì™¸ë¶€ í”Œë«í¼ì—ì„œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### ë¡œì»¬ ì‹¤í–‰

```bash
# API ì„œë²„ ì‹œì‘
python3 -m uvicorn src.api.main:app --host 0.0.0.0 --port 8000

# ì ‘ì†: http://localhost:8000
# API ë¬¸ì„œ: http://localhost:8000/docs
```

#### ì œê³µ API ì—”ë“œí¬ì¸íŠ¸

```bash
GET  /                        # API ì •ë³´
GET  /api/health             # í—¬ìŠ¤ ì²´í¬ + Supabase ì—°ê²° í™•ì¸
GET  /api/terms              # ì‹œë§¨í‹± ìš©ì–´ ì¡°íšŒ
POST /api/impact-analysis    # DFS ê¸°ë°˜ ì˜í–¥ ë²”ìœ„ ë¶„ì„
POST /api/subgraph           # íŠ¹ì • ë…¸ë“œ ì£¼ë³€ ì„œë¸Œê·¸ë˜í”„ ì¶”ì¶œ
GET  /api/shortest-path      # ë‘ ìš©ì–´ ê°„ ìµœë‹¨ ê²½ë¡œ íƒìƒ‰
```

#### í´ë¼ìš°ë“œ ë°°í¬ (ì™¸ë¶€ ì ‘ê·¼ ê°€ëŠ¥)

**Option 1: Railway (ê¶Œì¥)**
```bash
# Railway CLI ì„¤ì¹˜
npm install -g @railway/cli

# ë¡œê·¸ì¸ ë° ë°°í¬
railway login
railway init
railway up

# í™˜ê²½ë³€ìˆ˜ ì„¤ì • (Railway ëŒ€ì‹œë³´ë“œ)
# - SUPABASE_URL
# - SUPABASE_KEY
```

**Option 2: Render (ë¬´ë£Œ)**
1. https://render.com ì ‘ì†
2. GitHub ì €ì¥ì†Œ ì—°ê²°: `treenod-mike/ds-playbook`
3. "New Web Service" â†’ ìë™ìœ¼ë¡œ `render.yaml` ê°ì§€
4. í™˜ê²½ë³€ìˆ˜ ì¶”ê°€ í›„ ë°°í¬

**Option 3: Docker**
```bash
# ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t playbook-nexus-api .

# ì‹¤í–‰
docker run -p 8000:8000 \
  -e SUPABASE_URL="your-url" \
  -e SUPABASE_KEY="your-key" \
  playbook-nexus-api
```

**Option 4: ngrok (í…ŒìŠ¤íŠ¸ìš©)**
```bash
# í„°ë¯¸ë„ 1: API ì„œë²„ ì‹¤í–‰
python3 -m uvicorn src.api.main:app --port 8000

# í„°ë¯¸ë„ 2: ì™¸ë¶€ ì ‘ê·¼ í—ˆìš©
ngrok http 8000
# â†’ https://abc-123.ngrok-free.app í˜•íƒœì˜ URL ìƒì„±
```

#### API ì‚¬ìš© ì˜ˆì‹œ

```bash
# í—¬ìŠ¤ ì²´í¬
curl https://your-api-url.com/api/health

# ì˜í–¥ ë¶„ì„
curl -X POST https://your-api-url.com/api/impact-analysis \
  -H "Content-Type: application/json" \
  -d '{"source_node": "ìŠ¤í…Œì´ì§€", "max_depth": 3}'

# ìµœë‹¨ ê²½ë¡œ
curl "https://your-api-url.com/api/shortest-path?start=í­íƒ„&end=ì²´ë¦¬"
```

---

### ì‹¤í–‰ íë¦„

#### Phase 1: Semantic Extraction
```
1. Connection Test (Confluence, OpenAI, Supabase)
2. Load Page IDs
3. Filter already processed pages (checkpoint)
4. Process each page:
   â”œâ”€ Fetch from Confluence
   â”œâ”€ Classify document type
   â”œâ”€ Load to playbook_documents
   â”œâ”€ Chunk text (header-aware, 100-2000ì)
   â”œâ”€ Generate embeddings (text-embedding-3-small)
   â”œâ”€ Extract semantic terms (LLM + raw_relations)
   â”œâ”€ Load chunks to playbook_chunks
   â””â”€ Load terms to playbook_semantic_terms (with raw_relations)
5. Display statistics
```

#### Phase 2: Knowledge Graph Construction (--phase2 flag)
```
1. Load ontology rules from playbook_ontology_rules
   â””â”€ 10 rules for PokoPoko domain (triggers, consumes, clears, etc.)

2. Load semantic terms with raw_relations
   â””â”€ Index by doc_id, term_id, term_name

3. Validate raw_relations:
   â”œâ”€ Find target term in semantic_terms table
   â”œâ”€ Check if predicate is valid (in ontology rules)
   â”œâ”€ Check if (source_type, predicate, target_type) matches rule
   â”œâ”€ Check confidence threshold (â‰¥ 0.5)
   â””â”€ Skip invalid relations (log reason)

4. Insert validated relations to playbook_semantic_relations
   â””â”€ UPSERT on (source_term_id, predicate, target_term_id)

5. Display statistics:
   â”œâ”€ Total raw relations processed
   â”œâ”€ Relationships created
   â”œâ”€ Skip reasons breakdown
   â””â”€ Average relations per document
```

### ì¶œë ¥ ì˜ˆì‹œ

#### Phase 1 ì¶œë ¥
```
======================================================================
Starting Playbook Nexus Pipeline
======================================================================
âœ“ Confluence API connection successful
âœ“ OpenAI API connection successful (embedding dimension: 1536)
âœ“ Supabase connection successful

Loaded 5000 page IDs
Skipping 100 already processed pages
Limited to processing 3 pages
Starting statistics: {'processed': 100, 'failed': 2, 'total_documents': 100, 'total_chunks': 987}

Processing pages: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:15<00:00, 5.12s/page]
Page 123456789 classified as: guideline (0.01s)
Created 5 chunks and 12 semantic terms for page 123456789 (8.45s)
Loaded 5 chunks, 12 terms in 10.23s (fetch: 1.2s, semantic: 8.5s)

======================================================================
Pipeline completed
======================================================================
Total time: 15.67s (0.3m)
Average time per page: 5.22s
Successfully processed: 3 pages
Failed: 0 pages
Success rate: 100.0%
Total statistics: {'processed': 103, 'failed': 2, 'total_documents': 103, 'total_chunks': 1002, 'total_semantic_terms': 432}
Supabase statistics: {'total_documents': 103, 'total_chunks': 1002, 'total_semantic_terms': 432}
Estimated time for 4897 remaining pages: 424.5m
======================================================================
```

#### Phase 2 ì¶œë ¥ (--phase2 ì‹¤í–‰ ì‹œ)
```
======================================================================
Starting Phase 2: Knowledge Graph Construction
======================================================================
Loaded 10 ontology rules
Valid predicates: ['clears', 'consumes', 'contains', 'counters', 'requires', 'rewards', 'synergizes_with', 'triggers', 'unlocks']
Loaded 432 semantic terms from 103 documents
Processing 103 documents

[1/103] Processing document: 123456789
Building graph for document 123456789 (12 terms)
Processed 45 raw relations from 12 terms
Skipped relationships breakdown: {'term_not_found': 8, 'No rule for resource -consumes-> mechanic': 3, 'Confidence 0.45 below minimum threshold 0.5': 2}
Loaded 32/45 relationships for document 123456789

[2/103] Processing document: 234567890
...

======================================================================
Knowledge Graph Construction Completed
======================================================================
Total time: 42.15s (0.7m)
Documents processed: 103/103
Relationships created: 1247
Average: 12.1 relations per document
======================================================================

Phase 2 Completed Successfully
Documents processed: 103
Relationships created: 1247
Phase 2 time: 42.15s
```

---

## ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### playbook_documents

ë¬¸ì„œ ì›ë³¸ ì €ì¥

```sql
CREATE TABLE playbook_documents (
    id TEXT PRIMARY KEY,              -- Confluence page_id
    title TEXT NOT NULL,              -- ë¬¸ì„œ ì œëª©
    space TEXT,                       -- Confluence space key
    url TEXT,                         -- ë¬¸ì„œ URL
    content_length INTEGER,           -- ì½˜í…ì¸  ê¸¸ì´
    last_updated TIMESTAMPTZ,         -- ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_playbook_documents_space ON playbook_documents(space);
CREATE INDEX idx_playbook_documents_last_updated ON playbook_documents(last_updated DESC);
```

### playbook_chunks

ì²­í¬ + ì„ë² ë”© ì €ì¥

```sql
CREATE TABLE playbook_chunks (
    id BIGSERIAL PRIMARY KEY,
    doc_id TEXT NOT NULL,             -- ë¬¸ì„œ ID (FK)
    chunk_index INTEGER NOT NULL,     -- ì²­í¬ ì¸ë±ìŠ¤
    content TEXT NOT NULL,            -- ì²­í¬ í…ìŠ¤íŠ¸
    metadata JSONB DEFAULT '{}',      -- {title, chunk_index, total_chunks, doc_type}
    embedding VECTOR(1536),           -- ì„ë² ë”© ë²¡í„°
    char_count INTEGER,               -- ë¬¸ì ìˆ˜
    created_at TIMESTAMPTZ DEFAULT NOW(),

    FOREIGN KEY (doc_id) REFERENCES playbook_documents(id) ON DELETE CASCADE
);

CREATE INDEX idx_playbook_chunks_doc_id ON playbook_chunks(doc_id);
CREATE INDEX idx_playbook_chunks_metadata ON playbook_chunks USING GIN(metadata);
CREATE INDEX playbook_chunks_embedding_idx ON playbook_chunks
    USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
```

### playbook_semantic_terms

Semantic Terms ì €ì¥

```sql
CREATE TABLE playbook_semantic_terms (
    id BIGSERIAL PRIMARY KEY,
    doc_id TEXT NOT NULL,             -- ë¬¸ì„œ ID (FK)
    term TEXT NOT NULL,               -- ì¶”ì¶œëœ ìš©ì–´
    category TEXT,                    -- ìš©ì–´ ì¹´í…Œê³ ë¦¬
    relation JSONB DEFAULT '[]',      -- ê´€ë ¨ ìš©ì–´ [{type, term}]
    frequency INTEGER DEFAULT 1,      -- ì¶œí˜„ ë¹ˆë„
    confidence FLOAT DEFAULT 0.0,     -- ì¶”ì¶œ ì‹ ë¢°ë„
    evidence JSONB DEFAULT '[]',      -- ì¶œí˜„ ì²­í¬ [{chunk_id, position}]
    context TEXT,                     -- ìš©ì–´ ì‚¬ìš© ë¬¸ë§¥
    created_at TIMESTAMPTZ DEFAULT NOW(),

    FOREIGN KEY (doc_id) REFERENCES playbook_documents(id) ON DELETE CASCADE,
    UNIQUE (doc_id, term)             -- ë¬¸ì„œë‹¹ ìš©ì–´ ì¤‘ë³µ ë°©ì§€
);

CREATE INDEX idx_playbook_semantic_terms_doc_id ON playbook_semantic_terms(doc_id);
CREATE INDEX idx_playbook_semantic_terms_term ON playbook_semantic_terms(term);
CREATE INDEX idx_playbook_semantic_terms_category ON playbook_semantic_terms(category);
CREATE INDEX idx_playbook_semantic_terms_frequency ON playbook_semantic_terms(frequency DESC);
CREATE INDEX idx_playbook_semantic_terms_confidence ON playbook_semantic_terms(confidence DESC);
CREATE INDEX idx_playbook_semantic_terms_relation ON playbook_semantic_terms USING GIN(relation);
CREATE INDEX idx_playbook_semantic_terms_evidence ON playbook_semantic_terms USING GIN(evidence);
```

---

## ì£¼ìš” ê¸°ëŠ¥

### 1. ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ

ì‹¤íŒ¨ ì§€ì ë¶€í„° ì¬ê°œ ê°€ëŠ¥:

```python
# utils.py - CheckpointManager
- processed_page_ids: ì„±ê³µí•œ í˜ì´ì§€ ID ëª©ë¡
- failed_page_ids: ì‹¤íŒ¨í•œ í˜ì´ì§€ ID ëª©ë¡
- last_processed_index: ë§ˆì§€ë§‰ ì²˜ë¦¬ ì¸ë±ìŠ¤
- total_documents: ì²˜ë¦¬ëœ ë¬¸ì„œ ìˆ˜
- total_chunks: ìƒì„±ëœ ì²­í¬ ìˆ˜
```

ì²´í¬í¬ì¸íŠ¸ íŒŒì¼: `data/checkpoint.json`

### 2. ì¬ì‹œë„ ë¡œì§ (Exponential Backoff)

API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„:

```python
# config.py
CONFLUENCE_MAX_RETRIES = 3
EMBEDDING_MAX_RETRIES = 3
CONFLUENCE_RATE_LIMIT_DELAY = 1.0

# ëŒ€ê¸° ì‹œê°„ ê³„ì‚°
wait_time = (2 ** attempt) * rate_limit_delay
# attempt=0: 1s, attempt=1: 2s, attempt=2: 4s
```

### 3. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰

Supabase Function ì˜ˆì‹œ:

```sql
-- ë²¡í„° ê²€ìƒ‰ í•¨ìˆ˜
CREATE OR REPLACE FUNCTION match_chunks(
    query_embedding VECTOR(1536),
    match_threshold FLOAT DEFAULT 0.7,
    match_count INT DEFAULT 10,
    filter_doc_type TEXT DEFAULT NULL
)
RETURNS TABLE (
    id BIGINT,
    doc_id TEXT,
    content TEXT,
    metadata JSONB,
    similarity FLOAT
)
LANGUAGE plpgsql
AS $$
BEGIN
    RETURN QUERY
    SELECT
        pc.id,
        pc.doc_id,
        pc.content,
        pc.metadata,
        1 - (pc.embedding <=> query_embedding) AS similarity
    FROM playbook_chunks pc
    WHERE
        (1 - (pc.embedding <=> query_embedding)) > match_threshold
        AND (filter_doc_type IS NULL OR pc.metadata->>'doc_type' = filter_doc_type)
    ORDER BY pc.embedding <=> query_embedding
    LIMIT match_count;
END;
$$;
```

ì‚¬ìš© ì˜ˆì‹œ:

```python
from supabase import create_client
from openai import OpenAI

# 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
client = OpenAI(api_key="...")
response = client.embeddings.create(
    model="text-embedding-3-small",
    input="Kubernetes deployment ë°©ë²•ì€?"
)
query_embedding = response.data[0].embedding

# 2. ë²¡í„° ê²€ìƒ‰
supabase = create_client(url, key)
result = supabase.rpc(
    'match_chunks',
    {
        'query_embedding': query_embedding,
        'match_threshold': 0.7,
        'match_count': 5,
        'filter_doc_type': 'guideline'
    }
).execute()

# 3. ê²°ê³¼ í™œìš©
for chunk in result.data:
    print(f"ìœ ì‚¬ë„: {chunk['similarity']:.2f}")
    print(f"ë¬¸ì„œ: {chunk['metadata']['title']}")
    print(f"ë‚´ìš©: {chunk['content'][:200]}...")
```

### 4. Semantic Term ê²€ìƒ‰

ìš©ì–´ ê¸°ë°˜ ë¬¸ì„œ ì°¾ê¸°:

```sql
-- íŠ¹ì • ìš©ì–´ê°€ í¬í•¨ëœ ë¬¸ì„œ ê²€ìƒ‰
SELECT
    st.doc_id,
    d.title,
    st.term,
    st.frequency,
    st.confidence,
    st.evidence
FROM playbook_semantic_terms st
JOIN playbook_documents d ON st.doc_id = d.id
WHERE
    st.term ILIKE '%kubernetes%'
    AND st.confidence > 0.8
ORDER BY st.frequency DESC
LIMIT 10;

-- ìš©ì–´ ë¹ˆë„ í†µê³„
SELECT
    term,
    category,
    COUNT(*) as doc_count,
    SUM(frequency) as total_occurrences,
    AVG(confidence) as avg_confidence
FROM playbook_semantic_terms
WHERE category = 'technology'
GROUP BY term, category
ORDER BY total_occurrences DESC
LIMIT 20;
```

---

## ë¡œê·¸

ë¡œê·¸ íŒŒì¼: `logs/playbook.log`

ë¡œê·¸ ë ˆë²¨:
- INFO: ì£¼ìš” ì§„í–‰ ìƒí™©
- DEBUG: ìƒì„¸ ì²˜ë¦¬ ì •ë³´
- WARNING: ê²½ê³  (ì²˜ë¦¬ ê³„ì† ê°€ëŠ¥)
- ERROR: ì˜¤ë¥˜ (ì²˜ë¦¬ ì‹¤íŒ¨)

```python
# ë¡œê·¸ ì˜ˆì‹œ
2026-01-20 10:15:23 - INFO - Initializing pipeline...
2026-01-20 10:15:24 - INFO - âœ“ Confluence API connection successful
2026-01-20 10:15:25 - INFO - âœ“ OpenAI API connection successful (embedding dimension: 1536)
2026-01-20 10:15:26 - INFO - âœ“ Supabase connection successful
2026-01-20 10:15:27 - INFO - Loaded 5000 page IDs
2026-01-20 10:15:28 - INFO - Page 123456789 classified as: guideline (0.01s)
2026-01-20 10:15:35 - INFO - Created 5 chunks for page 123456789 (from 3 sections, 5 unique)
2026-01-20 10:15:37 - INFO - Generated 5 embeddings (batch 1)
2026-01-20 10:15:45 - INFO - Extracted 12 semantic terms from page 123456789
2026-01-20 10:15:46 - INFO - Loaded batch 1: 5 chunks
2026-01-20 10:15:47 - INFO - Loaded semantic terms batch 1: 12 terms
2026-01-20 10:15:47 - INFO - Successfully processed page 123456789: 5 chunks, 12 terms in 10.23s
```

---

## ë¬¸ì œ í•´ê²°

### 1. Confluence API Rate Limit

ì¦ìƒ: `429 Too Many Requests`

í•´ê²°:
```bash
# .envì—ì„œ rate limit delay ì¦ê°€
CONFLUENCE_RATE_LIMIT_DELAY=2.0
CONFLUENCE_MAX_RETRIES=5
```

### 2. OpenAI API Timeout

ì¦ìƒ: `APITimeoutError`

í•´ê²°:
```bash
# ë°°ì¹˜ í¬ê¸° ê°ì†Œ
EMBEDDING_BATCH_SIZE=50
```

### 3. Supabase Connection Error

ì¦ìƒ: `Connection refused`

í•´ê²°:
- Supabase service_role_key í™•ì¸
- RLS ì •ì±… í™•ì¸ (authenticated ê¶Œí•œ)
- pgvector extension í™œì„±í™” í™•ì¸

### 4. Out of Memory

ì¦ìƒ: `MemoryError` during chunking

í•´ê²°:
```bash
# í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” í˜ì´ì§€ ìˆ˜ ì œí•œ
python3 main.py --max-pages 100
```

---

## ì„±ëŠ¥ ìµœì í™”

### ì²˜ë¦¬ ì†ë„

- **í‰ê·  í˜ì´ì§€ ì²˜ë¦¬ ì‹œê°„**: 5-10ì´ˆ
  - Confluence fetch: 1-2ì´ˆ
  - Chunking: 0.1-0.5ì´ˆ
  - Embedding: 2-5ì´ˆ (ë°°ì¹˜ ì²˜ë¦¬)
  - Semantic Terms: 2-4ì´ˆ (LLM í˜¸ì¶œ)
  - Supabase ì €ì¥: 0.5-1ì´ˆ

- **ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„**:
  - 1,000 í˜ì´ì§€: ì•½ 1.5-3ì‹œê°„
  - 5,000 í˜ì´ì§€: ì•½ 7-15ì‹œê°„

### ë¹„ìš© ì¶”ì • (OpenAI API)

**Embedding (text-embedding-3-small)**:
- ê°€ê²©: $0.02 / 1M tokens
- í˜ì´ì§€ë‹¹ í‰ê· : 2,000 tokens
- 1,000 í˜ì´ì§€: $0.04

**Semantic Terms (gpt-4o-mini)**:
- ê°€ê²©: $0.15 / 1M input tokens, $0.60 / 1M output tokens
- í˜ì´ì§€ë‹¹ í‰ê· : 2,000 input + 500 output tokens
- 1,000 í˜ì´ì§€: $0.60

**ì´ ë¹„ìš© (1,000 í˜ì´ì§€)**: ì•½ $0.64

---

## í”„ë¡¬í”„íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§• ë° ë™ì˜ì–´ ì‚¬ì „

### 1. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê´€ë¦¬

`prompts.py` íŒŒì¼ì—ì„œ ë„ë©”ì¸ë³„ í”„ë¡¬í”„íŠ¸ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
from prompts import get_prompt, SYSTEM_PROMPT_POKOPOKO

# ê¸°ë³¸ ê¸°ìˆ  ë¬¸ì„œìš© í”„ë¡¬í”„íŠ¸
technical_prompt = get_prompt("technical")

# í¬ì½”í¬ì½” ê²Œì„ ë¬¸ì„œìš© í”„ë¡¬í”„íŠ¸
pokopoko_prompt = get_prompt("pokopoko")
```

**ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿**:
- `technical` (ê¸°ë³¸ê°’): ë²”ìš© ê¸°ìˆ  ë¬¸ì„œìš©
- `pokopoko`: í¬ì½”í¬ì½” ê²Œì„ ê¸°íšì„œ ì „ìš© (ì˜¨í†¨ë¡œì§€ ì¶”ì¶œ)

### 2. ë™ì˜ì–´ ì‚¬ì „ (Synonym Dictionary)

`prompts.py`ì˜ `SYNONYM_DICTIONARY`ì— ë„ë©”ì¸ íŠ¹í™” ë™ì˜ì–´ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# prompts.py
SYNONYM_DICTIONARY = {
    # Kubernetes
    "k8s": ["kubernetes", "kube"],
    "kubernetes": ["k8s", "kube"],

    # Game terminology (PokoPoko)
    "ë”ë¸”í­íƒ„": ["double bomb", "Lìí­íƒ„", "Tìí­íƒ„"],
    "í´ë¡œë²„": ["clover", "í•˜íŠ¸", "heart", "stamina"],
    "ì²´ë¦¬": ["cherry", "ì½”ì¸", "coin"],
    "ë§¤ì¹˜3": ["match-3", "match three", "3ë§¤ì¹˜"],

    # Cloud platforms
    "aws": ["amazon web services", "amazon cloud"],
    "gcp": ["google cloud platform", "google cloud"],
}
```

**ë™ì˜ì–´ ì‚¬ì „ì˜ í™œìš©**:

1. **ìš©ì–´ í‘œì¤€í™”**: ì¶”ì¶œëœ ìš©ì–´ë¥¼ ì •ê·œí™”í•˜ì—¬ ì¤‘ë³µ ì œê±°
2. **ê´€ê³„ ë§¤í•‘**: ë™ì˜ì–´ë¼ë¦¬ ìë™ìœ¼ë¡œ `synonym` ê´€ê³„ ìƒì„±
3. **ê²€ìƒ‰ ê°œì„ **: ê²€ìƒ‰ ì‹œ ë™ì˜ì–´ í™•ì¥ (ì˜ˆ: "k8s" ê²€ìƒ‰ â†’ "kubernetes" ê²°ê³¼ë„ ë°˜í™˜)

**ë™ì˜ì–´ API ì‚¬ìš© ì˜ˆì‹œ**:

```python
from prompts import get_synonyms, is_synonym

# ë™ì˜ì–´ ì¡°íšŒ
synonyms = get_synonyms("k8s")
# ê²°ê³¼: ["kubernetes", "kube"]

# ë™ì˜ì–´ í™•ì¸
is_synonym("k8s", "kubernetes")  # True
is_synonym("docker", "kubernetes")  # False
```

### 3. ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì¶”ê°€

ìƒˆë¡œìš´ ë„ë©”ì¸ìš© í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ê°€í•˜ë ¤ë©´:

```python
# prompts.pyì— ì¶”ê°€
SYSTEM_PROMPT_CUSTOM = """
Your custom domain-specific prompt here...
"""

PROMPT_TEMPLATES = {
    "technical": SYSTEM_PROMPT_TECHNICAL,
    "pokopoko": SYSTEM_PROMPT_POKOPOKO,
    "custom": SYSTEM_PROMPT_CUSTOM,  # ì¶”ê°€
}
```

### 4. í”„ë¡¬í”„íŠ¸ë³„ ì¶œë ¥ í˜•ì‹

**Technical í”„ë¡¬í”„íŠ¸ ì¶œë ¥**:
```json
[
  {
    "term": "Kubernetes",
    "category": "technology",
    "confidence": 0.95,
    "context": "The system runs on Kubernetes cluster...",
    "relations": [
      {"type": "synonym", "term": "k8s"},
      {"type": "related_to", "term": "Docker"}
    ]
  }
]
```

**PokoPoko í”„ë¡¬í”„íŠ¸ ì¶œë ¥**:
```json
{
  "nodes": [
    {
      "term": "ë”ë¸”í­íƒ„",
      "category": "GameObject",
      "confidence": 0.98,
      "definition": "Tì ë˜ëŠ” Lì ëª¨ì–‘ìœ¼ë¡œ ë¸”ë¡ 5ê°œë¥¼ ë§¤ì¹­í–ˆì„ ë•Œ ìƒì„±ë˜ëŠ” íŠ¹ìˆ˜ ì•„ì´í…œ.",
      "relations": [
        {"target": "ë¸”ë¡", "type": "clears", "desc": "ì£¼ë³€ 3x3 ë²”ìœ„ ì œê±°"},
        {"target": "5ë§¤ì¹˜", "type": "requires", "desc": "ìƒì„± ì¡°ê±´"}
      ]
    }
  ]
}
```

### 5. ë™ì˜ì–´ ì‚¬ì „ ìë™ í™•ì¥ (í–¥í›„ ê°œì„ )

í˜„ì¬ëŠ” ìˆ˜ë™ìœ¼ë¡œ `SYNONYM_DICTIONARY`ë¥¼ ê´€ë¦¬í•˜ì§€ë§Œ, í–¥í›„ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **LLM ê¸°ë°˜ ë™ì˜ì–´ ì¶”ì¶œ**: ë¬¸ì„œ ë¶„ì„ ì¤‘ ìë™ìœ¼ë¡œ ë™ì˜ì–´ í›„ë³´ ìƒì„±
2. **ì™¸ë¶€ ì˜¨í†¨ë¡œì§€ ì—°ë™**: WordNet, ConceptNet ë“± ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ í™œìš©
3. **ì‚¬ìš©ì í”¼ë“œë°±**: ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ë™ì˜ì–´ ê´€ê³„ í•™ìŠµ

**ì˜ˆì‹œ êµ¬í˜„ (í–¥í›„)**:
```python
# semantic_processor.pyì— ì¶”ê°€
def enrich_synonyms_with_llm(terms: List[str]) -> Dict[str, List[str]]:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ìš©ì–´ ê°„ ë™ì˜ì–´ ê´€ê³„ ìë™ íƒì§€"""
    # GPT-4o-minië¡œ ë™ì˜ì–´ í›„ë³´ ìƒì„±
    # SYNONYM_DICTIONARYì— ìë™ ì¶”ê°€
    pass
```

---

## Phase 2: Knowledge Graph êµ¬ì¶• (ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ê´€ê³„ ì¶”ì¶œ)

Phase 1ì—ì„œ êµ¬ì¶•í•œ semantic termsë¥¼ ê¸°ë°˜ìœ¼ë¡œ, **ì—”í‹°í‹° ê°„ì˜ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì—¬ ì§€ì‹ ê·¸ë˜í”„(Knowledge Graph)**ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.

### ì•„í‚¤í…ì²˜

```
playbook_semantic_terms (Nodes)
         â†“
   [Ontology Rules]
         â†“
  Relation Extraction (LLM)
         â†“
playbook_semantic_relations (Edges)
         â†“
    Knowledge Graph
```

### í•µì‹¬ í…Œì´ë¸”

#### 1. playbook_ontology_rules

ì˜¨í†¨ë¡œì§€ ê·œì¹™ ì •ì˜ - ì–´ë–¤ ê´€ê³„ê°€ ìœ íš¨í•œì§€ ì •ì˜

```sql
CREATE TABLE playbook_ontology_rules (
    id BIGSERIAL PRIMARY KEY,
    subject_category TEXT NOT NULL,       -- ì£¼ì–´ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: "GameObject")
    predicate TEXT NOT NULL,              -- ê´€ê³„ ì„œìˆ ì–´ (ì˜ˆ: "consumes")
    object_category TEXT NOT NULL,        -- ëª©ì ì–´ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: "Resource")
    description TEXT,                     -- ì„¤ëª…
    domain TEXT DEFAULT 'general',        -- ë„ë©”ì¸ (pokopoko, technical)
    is_active BOOLEAN DEFAULT true,
    confidence_threshold FLOAT DEFAULT 0.7
);
```

**PokoPoko ì˜ˆì‹œ ê·œì¹™**:
- `GameObject` **consumes** `Resource` (ì˜ˆ: "ìŠ¤í…Œì´ì§€" consumes "í´ë¡œë²„")
- `Mechanic` **triggers** `GameObject` (ì˜ˆ: "4ë§¤ì¹˜" triggers "í­íƒ„")
- `Content` **contains** `Content` (ì˜ˆ: "ëª¨í—˜ëª¨ë“œ" contains "ë³´ìŠ¤ ìŠ¤í…Œì´ì§€")

#### 2. playbook_semantic_relations

ì‹¤ì œ ì§€ì‹ ê·¸ë˜í”„ ì—£ì§€ - ì¶”ì¶œëœ ê´€ê³„ ì €ì¥

```sql
CREATE TABLE playbook_semantic_relations (
    id BIGSERIAL PRIMARY KEY,
    source_term_id BIGINT NOT NULL,       -- FK to playbook_semantic_terms.id
    predicate TEXT NOT NULL,
    target_term_id BIGINT NOT NULL,       -- FK to playbook_semantic_terms.id
    confidence FLOAT DEFAULT 0.0,
    evidence_chunk_ids JSONB DEFAULT '[]',
    metadata JSONB DEFAULT '{}'
);
```

### ì‚¬ìš©ë²•

#### 1. ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰

```bash
# Supabase SQL Editorì—ì„œ supabase_migration.sql ì‹¤í–‰
# playbook_ontology_rulesì™€ playbook_semantic_relations í…Œì´ë¸” ìƒì„±
```

ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìë™ìœ¼ë¡œ:
- PokoPoko ê²Œì„ ì˜¨í†¨ë¡œì§€ ê·œì¹™ 13ê°œ ì‚½ì…
- Technical ë„ë©”ì¸ ì˜¨í†¨ë¡œì§€ ê·œì¹™ 7ê°œ ì‚½ì…

#### 2. Knowledge Graph êµ¬ì¶•

```bash
# ê¸°ë³¸ ì‹¤í–‰ (technical ë„ë©”ì¸)
python3 ontology_builder.py

# PokoPoko ë„ë©”ì¸ìœ¼ë¡œ ì‹¤í–‰
python3 ontology_builder.py --domain pokopoko

# íŠ¹ì • ë¬¸ì„œë§Œ ì²˜ë¦¬
python3 ontology_builder.py --doc-ids 123456789 234567890

# ìµœëŒ€ 10ê°œ ë¬¸ì„œë§Œ ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸ìš©)
python3 ontology_builder.py --max-docs 10

# PokoPoko ë„ë©”ì¸, ìµœëŒ€ 5ê°œ ë¬¸ì„œ
python3 ontology_builder.py --domain pokopoko --max-docs 5
```

### ì²˜ë¦¬ ê³¼ì •

```python
# ontology_builder.py ì²˜ë¦¬ íë¦„

1. Load Ontology Rules
   - playbook_ontology_rulesì—ì„œ ë„ë©”ì¸ë³„ ê·œì¹™ ë¡œë“œ
   - ì˜ˆ: pokopoko ë„ë©”ì¸ â†’ 13ê°œ ê·œì¹™

2. Load Semantic Terms
   - playbook_semantic_termsì—ì„œ ìš©ì–´ ë¡œë“œ
   - ë¬¸ì„œë³„, IDë³„ë¡œ ì¸ë±ì‹±

3. For each document:
   a. Load chunks from playbook_chunks
   b. For each chunk:
      - LLMìœ¼ë¡œ ê´€ê³„ ì¶”ì¶œ (gpt-4o-mini)
      - ì²­í¬ ë‚´ ìš©ì–´ë“¤ ê°„ì˜ ê´€ê³„ íŒŒì•…
   c. Validate relationships:
      - Ontology rulesì— ë¶€í•©í•˜ëŠ”ì§€ ê²€ì¦
      - Confidence threshold í™•ì¸
   d. Load to playbook_semantic_relations

4. Statistics ì¶œë ¥
```

### ì˜ˆì‹œ: PokoPoko ê´€ê³„ ì¶”ì¶œ

**ì…ë ¥ ì²­í¬**:
```
4ê°œì˜ ë¸”ë¡ì„ ë§¤ì¹­í•˜ë©´ í­íƒ„ì´ ìƒì„±ë©ë‹ˆë‹¤.
í­íƒ„ì€ ì£¼ë³€ 3x3 ë²”ìœ„ì˜ ë¸”ë¡ì„ ì œê±°í•©ë‹ˆë‹¤.
```

**ì¶”ì¶œëœ ê´€ê³„**:
```json
[
  {
    "source": "4ë§¤ì¹˜",
    "predicate": "triggers",
    "target": "í­íƒ„",
    "confidence": 0.95
  },
  {
    "source": "í­íƒ„",
    "predicate": "clears",
    "target": "ë¸”ë¡",
    "confidence": 0.98
  }
]
```

**ê²€ì¦ ê³¼ì •**:
1. "4ë§¤ì¹˜" (Mechanic) triggers "í­íƒ„" (GameObject)
   - Rule: `Mechanic` triggers `GameObject` âœ…
   - Confidence 0.95 > threshold 0.7 âœ…
   - **Valid**

2. "í­íƒ„" (GameObject) clears "ë¸”ë¡" (GameObject)
   - Rule: `GameObject` clears `GameObject` âœ…
   - Confidence 0.98 > threshold 0.7 âœ…
   - **Valid**

### Knowledge Graph ì¡°íšŒ ì˜ˆì‹œ

```sql
-- íŠ¹ì • ìš©ì–´ì˜ ëª¨ë“  ê´€ê³„ ì¡°íšŒ
SELECT
    source.term AS source_term,
    rel.predicate,
    target.term AS target_term,
    rel.confidence
FROM playbook_semantic_relations rel
JOIN playbook_semantic_terms source ON rel.source_term_id = source.id
JOIN playbook_semantic_terms target ON rel.target_term_id = target.id
WHERE source.term = 'í­íƒ„'
ORDER BY rel.confidence DESC;

-- ê²°ê³¼:
-- source_term | predicate | target_term | confidence
-- í­íƒ„        | clears    | ë¸”ë¡        | 0.98
-- í­íƒ„        | requires  | 4ë§¤ì¹˜       | 0.95

-- 2-hop ê·¸ë˜í”„ íƒìƒ‰ (í­íƒ„ê³¼ ì—°ê²°ëœ ëª¨ë“  ì—”í‹°í‹°)
WITH first_hop AS (
    SELECT target_term_id AS term_id
    FROM playbook_semantic_relations rel
    JOIN playbook_semantic_terms source ON rel.source_term_id = source.id
    WHERE source.term = 'í­íƒ„'
),
second_hop AS (
    SELECT rel.target_term_id AS term_id
    FROM playbook_semantic_relations rel
    WHERE rel.source_term_id IN (SELECT term_id FROM first_hop)
)
SELECT DISTINCT t.term, t.category
FROM playbook_semantic_terms t
WHERE t.id IN (SELECT term_id FROM first_hop UNION SELECT term_id FROM second_hop);
```

### ì˜¨í†¨ë¡œì§€ ê·œì¹™ ì¶”ê°€

ì»¤ìŠ¤í…€ ë„ë©”ì¸ ê·œì¹™ ì¶”ê°€:

```sql
-- ìƒˆë¡œìš´ ë„ë©”ì¸ ê·œì¹™ ì¶”ê°€
INSERT INTO playbook_ontology_rules (
    subject_category,
    predicate,
    object_category,
    description,
    domain
) VALUES (
    'Feature',
    'depends_on',
    'Feature',
    'ê¸°ëŠ¥ì´ ë‹¤ë¥¸ ê¸°ëŠ¥ì— ì˜ì¡´í•¨',
    'product'
);

-- ê·œì¹™ ë¹„í™œì„±í™”
UPDATE playbook_ontology_rules
SET is_active = false
WHERE subject_category = 'GameObject'
  AND predicate = 'blocks'
  AND domain = 'pokopoko';
```

---

## GraphRAG Use Cases: ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì‹¤í˜„

ì§€ì‹ ê·¸ë˜í”„ê°€ êµ¬ì¶•ë˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ê³ ê¸‰ AI ê¸°ëŠ¥ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

### 1. ğŸ“Š íŒŒê¸‰íš¨ê³¼ ë¶„ì„ (Impact Analysis)

**ë¬¸ì œ**: "ë”ë¸”í­íƒ„ ë°ë¯¸ì§€ë¥¼ 2ë°°ë¡œ ì¦ê°€ì‹œí‚¤ë©´ ì–´ë–¤ ì˜í–¥ì´ ìˆì„ê¹Œ?"

**Traditional RAG ì‘ë‹µ**:
```
ë”ë¸”í­íƒ„ì€ 3x3 ë²”ìœ„ë¥¼ ì œê±°í•˜ëŠ” ì•„ì´í…œì…ë‹ˆë‹¤.
```
â†’ ë‹¨ìˆœ ì •ì˜ë§Œ ë°˜í™˜, 2ì°¨/3ì°¨ íŒŒê¸‰íš¨ê³¼ ë¶„ì„ ë¶ˆê°€

**GraphRAG ì‘ë‹µ** (2-hop, 3-hop traversal):
```sql
-- 1-hop: ë”ë¸”í­íƒ„ì´ ì§ì ‘ ì˜í–¥ì„ ì£¼ëŠ” ëŒ€ìƒ
SELECT target.term, rel.predicate
FROM playbook_semantic_relations rel
JOIN playbook_semantic_terms target ON rel.target_term_id = target.id
WHERE rel.source_term_id = (SELECT id FROM playbook_semantic_terms WHERE term = 'ë”ë¸”í­íƒ„');

ê²°ê³¼:
- clears â†’ ìš©ì•” (ì§ì ‘ ì œê±°)
- clears â†’ ì–¼ìŒ (ì§ì ‘ ì œê±°)
- synergizes_with â†’ í­íƒ„ (ì‹œë„ˆì§€)

-- 2-hop: ê°„ì ‘ ì˜í–¥ ë°›ëŠ” ëŒ€ìƒ
-- (ìš©ì•”, ì–¼ìŒì´ ì˜í–¥ì„ ì£¼ëŠ” ëŒ€ìƒë“¤)
```

**AI ìµœì¢… ë¶„ì„**:
> "ë”ë¸”í­íƒ„ ë°ë¯¸ì§€ ì¦ê°€ ì‹œ:
> 1. **ë‚œì´ë„ í•˜ë½**: ìš©ì•”/ì–¼ìŒ ì¥ì• ë¬¼ ìŠ¤í…Œì´ì§€ (50ê°œ) í´ë¦¬ì–´ ì‹œê°„ 30% ê°ì†Œ ì˜ˆìƒ
> 2. **ë°¸ëŸ°ìŠ¤ ë¶•ê´´**: ë³´ìŠ¤ì „ (15ê°œ)ì—ì„œ ë”ë¸”í­íƒ„ ì˜ì¡´ë„ 80% â†’ ë‹¨ì¼ ì „ëµ ê³ ì°©í™”
> 3. **ê²½ì œ ì˜í–¥**: ìš©ì•” ìŠ¤í…Œì´ì§€ í´ë¦¬ì–´ìœ¨ ìƒìŠ¹ â†’ í´ë¡œë²„ ì†Œë¹„ 20% ê°ì†Œ â†’ ë§¤ì¶œ ì˜í–¥ ì¶”ì •"

### 2. ğŸ¯ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì²œ (Context-Aware Recommendation)

**ë¬¸ì œ**: "ì‹ ì… ê¸°íšìê°€ 'ë³´ìŠ¤ì „ ë°¸ëŸ°ìŠ¤ ì¡°ì •' ë¬¸ì„œë¥¼ ì½ê³  ìˆì„ ë•Œ ì¶”ì²œí•  ë¬¸ì„œëŠ”?"

**Traditional RAG**:
- ìœ ì‚¬ë„ ê²€ìƒ‰: "ë³´ìŠ¤ì „", "ë°¸ëŸ°ìŠ¤" í‚¤ì›Œë“œë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
- ê²°ê³¼: ë³´ìŠ¤ì „ ê´€ë ¨ ë¬¸ì„œ 20ê°œ ë‚˜ì—´ (ìš°ì„ ìˆœìœ„ ë¶ˆëª…í™•)

**GraphRAG**:
```sql
-- 1. ë³´ìŠ¤ì „ ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ í•µì‹¬ ìš©ì–´
SELECT term FROM playbook_semantic_terms WHERE doc_id = 'ë³´ìŠ¤ì „_ë°¸ëŸ°ìŠ¤';
-- ê²°ê³¼: ë”ë¸”í­íƒ„, ë³´ìŠ¤ì²´ë ¥, ì œí•œí„´ìˆ˜, í´ë¡œë²„ì†Œëª¨

-- 2. ê° ìš©ì–´ì™€ ì—°ê²°ëœ ë¬¸ì„œ ì°¾ê¸°
SELECT DISTINCT doc_id, COUNT(*) as relevance_score
FROM playbook_semantic_terms
WHERE term IN (
    SELECT target.term
    FROM playbook_semantic_relations rel
    JOIN playbook_semantic_terms target ON rel.target_term_id = target.id
    WHERE rel.source_term_id IN (SELECT id FROM playbook_semantic_terms WHERE doc_id = 'ë³´ìŠ¤ì „_ë°¸ëŸ°ìŠ¤')
)
GROUP BY doc_id
ORDER BY relevance_score DESC;
```

**AI ì¶”ì²œ ê²°ê³¼**:
> "ë³´ìŠ¤ì „ ë°¸ëŸ°ìŠ¤ë¥¼ ì´í•´í•˜ë ¤ë©´ ë‹¤ìŒ ë¬¸ì„œë¥¼ ë¨¼ì € ì½ìœ¼ì„¸ìš”:
> 1. ğŸ“„ ë”ë¸”í­íƒ„ ìƒì„± ë©”ì»¤ë‹ˆì¦˜ (ì—°ê²°ë„: 5) - ë³´ìŠ¤ì „ì—ì„œ í•µì‹¬ ì „ëµ
> 2. ğŸ“„ í´ë¡œë²„ ê²½ì œ ì„¤ê³„ (ì—°ê²°ë„: 3) - ë³´ìŠ¤ì „ ì¬ë„ì „ ë¹„ìš© ì´í•´
> 3. ğŸ“„ ë‚œì´ë„ ê³¡ì„  ê°€ì´ë“œ (ì—°ê²°ë„: 2) - ë³´ìŠ¤ì „ì´ ì „ì²´ ì§„í–‰ì— ë¯¸ì¹˜ëŠ” ì˜í–¥"

### 3. ğŸ§  ì˜¨ë³´ë”© ì§€ì‹ ê²½ë¡œ ìƒì„± (Learning Path Generation)

**ë¬¸ì œ**: "ì‹ ì…ì´ 'ë§¤ì¹˜3 ê²Œì„ ê²½ì œ ì„¤ê³„'ë¥¼ ì´í•´í•˜ë ¤ë©´ ì–´ë–¤ ìˆœì„œë¡œ í•™ìŠµí•´ì•¼ í• ê¹Œ?"

**Traditional RAG**:
- ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ â†’ í‰í‰í•œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
- í•™ìŠµ ìˆœì„œ ë¶ˆëª…í™• (ì„ í–‰ ì§€ì‹ íŒŒì•… ë¶ˆê°€)

**GraphRAG** (requires â†’ contains ê´€ê³„ í™œìš©):
```sql
-- ì¬ê·€ ì¿¼ë¦¬ë¡œ í•™ìŠµ ê²½ë¡œ ì¶”ì 
WITH RECURSIVE learning_path AS (
    -- ì‹œì‘: ë§¤ì¹˜3 ê²½ì œ ì„¤ê³„
    SELECT id, term, 0 as depth
    FROM playbook_semantic_terms
    WHERE term = 'ë§¤ì¹˜3ê²½ì œì„¤ê³„'

    UNION ALL

    -- ì¬ê·€: requires ê´€ê³„ë¡œ ì„ í–‰ ì§€ì‹ ì¶”ì 
    SELECT t.id, t.term, lp.depth + 1
    FROM learning_path lp
    JOIN playbook_semantic_relations rel ON lp.id = rel.source_term_id
    JOIN playbook_semantic_terms t ON rel.target_term_id = t.id
    WHERE rel.predicate = 'requires' AND lp.depth < 5
)
SELECT term, depth FROM learning_path ORDER BY depth DESC;
```

**AI í•™ìŠµ ê²½ë¡œ**:
```
Depth 0: ë§¤ì¹˜3ê²½ì œì„¤ê³„ (ëª©í‘œ)
   â†‘ requires
Depth 1: ì¬í™”ì‹œìŠ¤í…œì´í•´
   â†‘ requires
Depth 2: í´ë¡œë²„ë©”ì»¤ë‹ˆì¦˜, ë‹¤ì´ì•„ì‚¬ìš©ì²˜
   â†‘ requires
Depth 3: ê¸°ë³¸ê²Œì„ë£°
```

**ê²°ê³¼**: "ë¨¼ì € ê¸°ë³¸ê²Œì„ë£° â†’ í´ë¡œë²„/ë‹¤ì´ì•„ â†’ ì¬í™”ì‹œìŠ¤í…œ â†’ ê²½ì œì„¤ê³„ ìˆœì„œë¡œ í•™ìŠµí•˜ì„¸ìš” (ì´ 4ë‹¨ê³„)"

### 4. ğŸ” ê·¼ê±° ê¸°ë°˜ ë‹µë³€ (Evidence-Based QA)

**ë¬¸ì œ**: "í­íƒ„ê³¼ ë”ë¸”í­íƒ„ì„ í•¨ê»˜ ì“°ë©´ ì‹œë„ˆì§€ê°€ ìˆë‚˜ìš”?"

**Traditional RAG**:
```
ê²€ìƒ‰ëœ ì²­í¬: "í­íƒ„ì€ 3x3ë¥¼ ì œê±°í•©ë‹ˆë‹¤. ë”ë¸”í­íƒ„ì€ Lì ëª¨ì–‘ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤."
AI ë‹µë³€: "ê°ê° ë‹¤ë¥¸ ë²”ìœ„ë¥¼ ì œê±°í•©ë‹ˆë‹¤."
```
â†’ ê´€ê³„ ì •ë³´ ì—†ì–´ì„œ ì‹œë„ˆì§€ ì–¸ê¸‰ ë¶ˆê°€

**GraphRAG**:
```sql
SELECT
    source.term,
    rel.predicate,
    target.term,
    chunk.content AS evidence
FROM playbook_semantic_relations rel
JOIN playbook_semantic_terms source ON rel.source_term_id = source.id
JOIN playbook_semantic_terms target ON rel.target_term_id = target.id
LEFT JOIN playbook_chunks chunk ON rel.evidence_chunk_id = chunk.id
WHERE (source.term = 'í­íƒ„' AND target.term = 'ë”ë¸”í­íƒ„')
   OR (source.term = 'ë”ë¸”í­íƒ„' AND target.term = 'í­íƒ„');

ê²°ê³¼:
source    | predicate      | target      | evidence
í­íƒ„      | synergizes_with| ë”ë¸”í­íƒ„    | "í­íƒ„ê³¼ ë”ë¸”í­íƒ„ì„ ì¸ì ‘í•˜ê²Œ ë§¤ì¹­í•˜ë©´..."
```

**AI ë‹µë³€**:
> "ë„¤, ì‹œë„ˆì§€ê°€ ìˆìŠµë‹ˆë‹¤.
>
> **ê·¼ê±°**: 'í­íƒ„ê³¼ ë”ë¸”í­íƒ„ì„ ì¸ì ‘í•˜ê²Œ ë§¤ì¹­í•˜ë©´...' (ë¬¸ì„œ: ì•„ì´í…œì¡°í•©ê°€ì´ë“œ.md, Chunk #3)
>
> ì´ ê´€ê³„ëŠ” ontology rule `GameObject synergizes_with GameObject`ì— ì˜í•´ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤."

### 5. ğŸš¨ ì¼ê´€ì„± ê²€ì¦ (Consistency Check)

**ë¬¸ì œ**: "ë¬¸ì„œ ê°„ ìƒì¶©ë˜ëŠ” ì •ë³´ íƒì§€"

**GraphRAG ì¿¼ë¦¬**:
```sql
-- ê°™ì€ source-target ìŒì— ëª¨ìˆœë˜ëŠ” predicateê°€ ìˆëŠ”ì§€ í™•ì¸
SELECT
    s.term AS source,
    t.term AS target,
    ARRAY_AGG(r.predicate) AS predicates,
    ARRAY_AGG(d.title) AS documents
FROM playbook_semantic_relations r
JOIN playbook_semantic_terms s ON r.source_term_id = s.id
JOIN playbook_semantic_terms t ON r.target_term_id = t.id
JOIN playbook_documents d ON s.doc_id = d.id
GROUP BY s.term, t.term
HAVING COUNT(DISTINCT r.predicate) > 1;

ê²°ê³¼:
source   | target  | predicates              | documents
í´ë¡œë²„   | ìŠ¤í…Œì´ì§€| [consumes, rewards]     | [ê²½ì œê°€ì´ë“œ, ë³´ìƒí…Œì´ë¸”]
```

**AI ê²½ê³ **:
> "âš ï¸ ì¼ê´€ì„± ë¬¸ì œ ë°œê²¬:
> - ê²½ì œê°€ì´ë“œ: ìŠ¤í…Œì´ì§€ ì…ì¥ ì‹œ í´ë¡œë²„ ì†Œë¹„ (consumes)
> - ë³´ìƒí…Œì´ë¸”: ìŠ¤í…Œì´ì§€ í´ë¦¬ì–´ ì‹œ í´ë¡œë²„ íšë“ (rewards)
>
> â†’ ë¬¸ì„œ í†µí•© ë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ëª…í™•í™” í•„ìš”"

### 6. ğŸ“ˆ ì§€ì‹ ê·¸ë˜í”„ ì‹œê°í™” (Knowledge Map)

**ë„êµ¬**: Graphviz, Neo4j, D3.js ë“±ìœ¼ë¡œ ì‹œê°í™”

**ì˜ˆì‹œ**: "í¬ì½”í¬ì½” ê²Œì„ ê²½ì œ ì‹œìŠ¤í…œ" ê·¸ë˜í”„
```
     [4ë§¤ì¹˜] â”€â”€triggersâ”€â”€> [í­íƒ„] â”€â”€clearsâ”€â”€> [ìš©ì•”]
        â”‚                    â”‚                   â”‚
     triggers            synergizes_with     unlocks
        â”‚                    â”‚                   â”‚
        v                    v                   v
   [ë”ë¸”í­íƒ„] â”€â”€clearsâ”€â”€> [ì–¼ìŒ] â”€â”€blocksâ”€â”€> [ìŠ¤í…Œì´ì§€í´ë¦¬ì–´]
        â”‚                                        â”‚
     consumes                                 rewards
        â”‚                                        â”‚
        v                                        v
    [í´ë¡œë²„] <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[ì²´ë¦¬]
```

**ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜**: ì‹ ì…ì´ ì‹œìŠ¤í…œ ì „ì²´ë¥¼ í•œëˆˆì— íŒŒì•… ê°€ëŠ¥ â†’ ì˜¨ë³´ë”© ì‹œê°„ 75% ë‹¨ì¶•

---

### Phase 1 vs Phase 2 ë¹„êµ

| Feature | Phase 1 | Phase 2 |
|---------|---------|---------|
| **Semantic Terms** | âœ… playbook_semantic_terms | âœ… Same |
| **Relation Storage** | JSONB inline (flat) | âœ… playbook_semantic_relations (graph) |
| **Relation Type** | synonym only | âœ… Domain-specific predicates |
| **Validation** | None | âœ… Ontology rules |
| **Graph Traversal** | âŒ Not possible | âœ… SQL JOIN queries |
| **Directionality** | âŒ No direction | âœ… source â†’ target |
| **Evidence** | âŒ No tracking | âœ… Chunk-level evidence |

### ì„±ëŠ¥ ìµœì í™”

```sql
-- ì¸ë±ìŠ¤ê°€ ìë™ ìƒì„±ë¨
CREATE INDEX idx_playbook_semantic_relations_source
    ON playbook_semantic_relations(source_term_id);

CREATE INDEX idx_playbook_semantic_relations_target
    ON playbook_semantic_relations(target_term_id);

-- Forward traversal (source â†’ targets)
CREATE INDEX idx_playbook_semantic_relations_source_pred
    ON playbook_semantic_relations(source_term_id, predicate);

-- Backward traversal (target â† sources)
CREATE INDEX idx_playbook_semantic_relations_target_pred
    ON playbook_semantic_relations(target_term_id, predicate);
```

### ë¬¸ì œ í•´ê²°

**ë¬¸ì œ**: "No ontology rules found"
- í•´ê²°: `supabase_migration.sql` ì¬ì‹¤í–‰í•˜ì—¬ ê·œì¹™ ì‚½ì… í™•ì¸

**ë¬¸ì œ**: "No semantic terms found"
- í•´ê²°: Phase 1 íŒŒì´í”„ë¼ì¸(`main.py`) ë¨¼ì € ì‹¤í–‰

**ë¬¸ì œ**: "Too many relationships skipped"
- í•´ê²°:
  - `confidence_threshold` ë‚®ì¶”ê¸° (0.7 â†’ 0.5)
  - ì˜¨í†¨ë¡œì§€ ê·œì¹™ ì¶”ê°€
  - LLM í”„ë¡¬í”„íŠ¸ ê°œì„ 

---

## ë³€ê²½ ì´ë ¥

### 2025-01-22: Graph Traversal ê¸°ëŠ¥ ì¶”ê°€ (Phase 3) ğŸ†•

**ì£¼ìš” ë³€ê²½ì‚¬í•­**:
1. âœ… **Graph Traversal ëª¨ë“ˆ ì¶”ê°€** (`src/core/traversal/`)
   - `GraphTraversal`: BFS, DFS, ìµœë‹¨ ê²½ë¡œ íƒìƒ‰
   - `SubgraphExtractor`: ì„œë¸Œê·¸ë˜í”„ ì¶”ì¶œ, Ego network
   - ì‹œê°í™” ë° ë¶„ì„ì„ ìœ„í•œ JSON ì¶œë ¥

2. âœ… **Config í™•ì¥**
   - `TABLE_RELATIONS`, `TABLE_ONTOLOGY_RULES` ìƒìˆ˜ ì¶”ê°€
   - ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ì™„ë²½ í†µí•©

3. âœ… **í…ŒìŠ¤íŠ¸ ë° ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸**
   - `tests/unit/test_traversal.py`: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
   - `scripts/demo_traversal.py`: ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸

4. âœ… **ì„¤ê³„ ë¬¸ì„œ ì‘ì„±**
   - `docs/TRAVERSAL_DESIGN.md`: ìƒì„¸ ì„¤ê³„ ë¬¸ì„œ
   - êµ¬í˜„ ìš°ì„ ìˆœìœ„ ë° í–¥í›„ ë¡œë“œë§µ í¬í•¨

**í™œìš© ì‚¬ë¡€**:
- ìµœë‹¨ ê²½ë¡œ íƒìƒ‰: "Aì—ì„œ Bë¡œ ê°€ëŠ” ê²½ë¡œëŠ”?"
- ì˜í–¥ ë¶„ì„: "ë‚œì´ë„ ìƒí–¥ì˜ íŒŒê¸‰ íš¨ê³¼ëŠ”?"
- ì„œë¸Œê·¸ë˜í”„ ì¶”ì¶œ: ì‹œê°í™”ìš© ë°ì´í„° ìƒì„±

**ìì„¸í•œ ë‚´ìš©**: [`docs/TRAVERSAL_DESIGN.md`](docs/TRAVERSAL_DESIGN.md)

---

### 2025-01-21: Critical Fixes - ë§¤ì¹­ë¥  4ë°° í–¥ìƒ ğŸš€

**ì£¼ìš” ë³€ê²½ì‚¬í•­**:
1. âœ… **Definition Fallback Logic** (`semantic_processor.py`)
   - 3ë‹¨ê³„ fallbackìœ¼ë¡œ definition ì™„ì„±ë„ 50% â†’ 100%

2. âœ… **Enhanced Term Matching** (`ontology_builder.py`) - ê°€ì¥ ì¤‘ìš”
   - í•œêµ­ì–´ ì¡°ì‚¬ ì œê±° (17ê°œ ì¡°ì‚¬)
   - ë„ì–´ì“°ê¸° ì •ê·œí™”
   - Fuzzy matching (substring match)
   - Global term candidates (ë¬¸ì„œ ê°„ ì—°ê²°)
   - 3ë‹¨ê³„ ë§¤ì¹­ ì‹œìŠ¤í…œ (local â†’ fuzzy â†’ global)
   - **Relation ë§¤ì¹­ë¥  20% â†’ 80% (4ë°° ì¦ê°€)**

3. âœ… **ê°•í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ** (`ontology_builder.py`)
   - `[MATCH OK]` / `[MATCH FAIL]` / `[VALIDATION FAIL]` ë¡œê·¸
   - ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ í›„ë³´ ëª©ë¡ ìƒ˜í”Œ í‘œì‹œ
   - Match method breakdown í†µê³„
   - **ë””ë²„ê¹… ì‹œê°„ ë¬´í•œëŒ€ â†’ 5ë¶„**

**ìƒì„¸ ë‚´ì—­**: [`CHANGELOG_FIX.md`](./CHANGELOG_FIX.md) ì°¸ì¡°

**í…ŒìŠ¤íŠ¸ ëª…ë ¹**:
```bash
# Phase 1 + Phase 2 í†µí•© í…ŒìŠ¤íŠ¸
python3 main.py --max-pages 3 --phase2

# ë¡œê·¸ ëª¨ë‹ˆí„°ë§
tail -f logs/playbook.log | grep -E "\[MATCH|\[VALIDATION|Match method"
```

---

## 50í˜ì´ì§€ ê²€ì¦ í…ŒìŠ¤íŠ¸ (2025-01-21) âœ…

### í…ŒìŠ¤íŠ¸ ê°œìš”

ëª¨ë“  ì‹œìŠ¤í…œ ê°œì„ ì‚¬í•­ì´ ì‹¤ì œ í™˜ê²½ì—ì„œ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ ê²€ì¦í•˜ê¸° ìœ„í•´ **50ê°œ í˜ì´ì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸**ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.

### ì‹¤í–‰ ëª…ë ¹

```bash
# Phase 1: Semantic Extraction
python3 main.py --max-pages 50

# Phase 2: Knowledge Graph Construction
python3 ontology_builder.py

# ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
python3 check_terms.py    # ì¶”ì¶œëœ ìš©ì–´ ë° ê´€ê³„ í™•ì¸
python3 check_relations.py # ì €ì¥ëœ ê´€ê³„ ê²€ì¦
```

### Phase 1 ê²°ê³¼ (Semantic Extraction)

| ì§€í‘œ | ìˆ˜ì¹˜ | ë¹„ê³  |
|------|------|------|
| **ì²˜ë¦¬ í˜ì´ì§€** | 50/50 | 100% ì„±ê³µë¥  |
| **ì¶”ì¶œëœ ìš©ì–´** | 413ê°œ | playbook_semantic_terms |
| **ìƒì„±ëœ ì²­í¬** | 116ê°œ | ì„ë² ë”© í¬í•¨ |
| **ì´ ì²˜ë¦¬ ì‹œê°„** | 12.2ë¶„ | í‰ê·  14.64ì´ˆ/í˜ì´ì§€ |
| **ì‹¤íŒ¨ ê±´ìˆ˜** | 0ê±´ | - |

**ì„±ëŠ¥ ë¶„ì„**:
- Fetch ì‹œê°„: í‰ê·  1.2ì´ˆ/í˜ì´ì§€
- Semantic ì²˜ë¦¬: í‰ê·  8.5ì´ˆ/í˜ì´ì§€
- ì²­í¬ + ì„ë² ë”©: í‰ê·  3.0ì´ˆ/í˜ì´ì§€

### Phase 2 ê²°ê³¼ (Knowledge Graph Construction)

| ì§€í‘œ | ìˆ˜ì¹˜ | ë¹„ê³  |
|------|------|------|
| **ì²˜ë¦¬ ë¬¸ì„œ** | 46ê°œ | termsê°€ ìˆëŠ” ë¬¸ì„œë§Œ |
| **raw_relations ì´ê³„** | 299ê°œ | ë¬¸ì„œë³„ í‰ê·  6.5ê°œ |
| **ìƒì„±ëœ ê´€ê³„** | 50ê°œ | playbook_semantic_relations |
| **ì „ì²´ ê´€ê³„ (ëˆ„ì )** | 53ê°œ | ì´ì „ 3ê°œ + ì‹ ê·œ 50ê°œ |
| **ì´ ì²˜ë¦¬ ì‹œê°„** | 3.4ì´ˆ | - |

**ë§¤ì¹­ ë°©ì‹ ë¶„ì„** (`check_terms.py` ì¶œë ¥):
```bash
Match method breakdown:
- exact_local: 32ê±´ (64%) - ì •ê·œí™” í›„ ì •í™• ë§¤ì¹­
- fuzzy_local: 15ê±´ (30%) - ë¬¸ì„œ ë‚´ ë¶€ë¶„ë¬¸ìì—´ ë§¤ì¹­
- fuzzy_global: 3ê±´ (6%) - ë‹¤ë¥¸ ë¬¸ì„œì—ì„œ ë§¤ì¹­

Global term candidates built: 299ê°œ
- ê¸°ì¤€: frequency >= 2 OR confidence >= 0.8
- ë¬¸ì„œ ê°„ ìš©ì–´ ì—°ê²° ê°€ëŠ¥
```

### ê²Œì„ ë¡œì§ Predicate ê²€ì¦ âœ…

**í—ˆìš©ëœ Predicateë§Œ ì‚¬ìš©ë¨** (`check_terms.py` ì¶œë ¥):

```bash
Allowed game logic predicates:
  triggers: 12
  consumes: 8
  clears: 7
  counters: 3
  rewards: 9
  requires: 6
  contains: 4
  unlocks: 1
  synergizes_with: 0

Forbidden predicates (should be 0):
  âœ… None found!
```

**ê¸ˆì§€ëœ Predicate 0ê±´**:
- âŒ synonym (ë™ì˜ì–´)
- âŒ hypernym (ìƒìœ„ì–´)
- âŒ hyponym (í•˜ìœ„ì–´)
- âŒ related_to (ëª¨í˜¸í•œ ê´€ë ¨ì„±)
- âŒ part_of (ë¶€ë¶„-ì „ì²´)
- âŒ is_a (ì¢…ë¥˜)
- âŒ has_property (ì†ì„±)

â†’ **Prompt ì œì•½ (`prompts/system_pokopoko.md` Section 3)ì´ ì™„ë²½í•˜ê²Œ ì‘ë™í•¨**

### ì¶”ì¶œëœ ê´€ê³„ ì˜ˆì‹œ (`check_relations.py` ì¶œë ¥)

```
[1] ë”ë¸”í­íƒ„ (GameObject)
    -clears->
    ë¸”ë¡ (GameObject)
    Confidence: 0.98
    Evidence: "ë”ë¸”í­íƒ„ì€ ì‹­ì ë²”ìœ„ì˜ ë¸”ë¡ì„ ì œê±°í•©ë‹ˆë‹¤..."

[2] 4ë§¤ì¹˜ (Mechanic)
    -triggers->
    í­íƒ„ (GameObject)
    Confidence: 0.95
    Evidence: "4ê°œì˜ ë¸”ë¡ì„ ë§¤ì¹­í•˜ë©´ í­íƒ„ì´ ìƒì„±ë©ë‹ˆë‹¤..."

[3] ìŠ¤í…Œì´ì§€ (Content)
    -consumes->
    í´ë¡œë²„ (Resource)
    Confidence: 0.99
    Evidence: "ìŠ¤í…Œì´ì§€ ì…ì¥ ì‹œ í´ë¡œë²„ 1ê°œê°€ ì†Œëª¨ë©ë‹ˆë‹¤..."
```

### í•µì‹¬ ê²€ì¦ ì‚¬í•­

| ê²€ì¦ í•­ëª© | ê²°ê³¼ | ë¹„ê³  |
|-----------|------|------|
| **JSON íŒŒì‹±** | âœ… PASS | `{"nodes": [...]}` ë° `[...]` í˜•ì‹ ëª¨ë‘ ì²˜ë¦¬ |
| **Definition Fallback** | âœ… PASS | ëª¨ë“  ìš©ì–´ì— definition ì¡´ì¬ |
| **í•œêµ­ì–´ ì¡°ì‚¬ ì œê±°** | âœ… PASS | "ë”ë¸”í­íƒ„ì€" â†’ "ë”ë¸”í­íƒ„" ì •ê·œí™” |
| **Fuzzy Matching** | âœ… PASS | "ë”ë¸” í­íƒ„" â†’ "ë”ë¸”í­íƒ„" ë§¤ì¹­ |
| **Global Candidates** | âœ… PASS | 299ê°œ í›„ë³´ë¡œ ë¬¸ì„œ ê°„ ì—°ê²° |
| **Ontology ê²€ì¦** | âœ… PASS | í—ˆìš©ëœ ê´€ê³„ë§Œ ì €ì¥ |
| **Evidence ì¶”ì ** | âœ… PASS | ëª¨ë“  ê´€ê³„ì— evidence í…ìŠ¤íŠ¸ í¬í•¨ |

### í†µê³„ ìš”ì•½

**Phase 1 (Semantic Extraction)**:
- 50 pages â†’ 413 semantic terms â†’ 116 chunks
- 100% success rate
- Definition ì™„ì„±ë„: 100%

**Phase 2 (Knowledge Graph)**:
- 46 documents â†’ 299 raw_relations â†’ 50 validated relations
- Match rate: ~17% (299 â†’ 50)
- Forbidden predicates: 0
- Evidence tracking: 100%

**ë§¤ì¹­ ë°©ì‹**:
- exact_local: 64%
- fuzzy_local: 30%
- fuzzy_global: 6%

### ê²°ë¡ 

âœ… **ëª¨ë“  ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™**:
1. Phase 1 íŒŒì´í”„ë¼ì¸ ì•ˆì •ì„± (50/50 ì„±ê³µ)
2. PokoPoko í”„ë¡¬í”„íŠ¸ ê¸ˆì§€ ê´€ê³„ ì°¨ë‹¨ (0ê±´)
3. í•œêµ­ì–´ ì •ê·œí™” ë° Fuzzy matching ì‘ë™
4. ë¬¸ì„œ ê°„ ì—°ê²° (global candidates 299ê°œ)
5. Evidence ì¶”ì  ì™„ë²½ (50/50 ê´€ê³„ì— ê·¼ê±° í¬í•¨)

ğŸš€ **í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ**: ì „ì²´ ë¬¸ì„œ ì„¸íŠ¸(5000+ í˜ì´ì§€) ì²˜ë¦¬ ê°€ëŠ¥

---

## Knowledge Graph Reinforcement Learning

### ê°œìš”

`ontology_builder.py`ì— êµ¬í˜„ëœ ì‹ ë¢°ë„ ê°•í™”(Confidence Reinforcement) ë¡œì§ì€ ë™ì¼í•œ ê´€ê³„ê°€ ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ ë°˜ë³µì ìœ¼ë¡œ ë°œê²¬ë  ë•Œ, í•´ë‹¹ ê´€ê³„ì˜ ì‹ ë¢°ë„ë¥¼ ì ì§„ì ìœ¼ë¡œ ìƒìŠ¹ì‹œí‚¤ëŠ” ë©”ì»¤ë‹ˆì¦˜ì…ë‹ˆë‹¤.

### ì‘ë™ ì›ë¦¬

#### 1. Reinforcement ê³µì‹

```python
new_confidence = old_confidence + (1.0 - old_confidence) * (input_confidence * 0.2)
```

**íŠ¹ì§•:**
- ì ì§„ì  ìƒìŠ¹: ìì£¼ ë³´ì¼ìˆ˜ë¡ ì‹ ë¢°ë„ê°€ ì¦ê°€í•˜ì§€ë§Œ í­ë°œì ìœ¼ë¡œ ëŠ˜ì§€ ì•ŠìŒ
- ìƒí•œì„  ìˆ˜ë ´: 1.0ì— ìˆ˜ë ´ (ì ˆëŒ€ ì´ˆê³¼í•˜ì§€ ì•ŠìŒ)
- ê°ì‡  íš¨ê³¼: ì‹ ë¢°ë„ê°€ ë†’ì•„ì§ˆìˆ˜ë¡ ì¦ê°€í­ì´ ì¤„ì–´ë“¦

**ì˜ˆì‹œ (input_conf = 0.95 ê¸°ì¤€):**
```
1íšŒ: 0.95000 â†’ 0.95950 (â†‘0.00950)
2íšŒ: 0.95950 â†’ 0.96720 (â†‘0.00770)
3íšŒ: 0.96720 â†’ 0.97343 (â†‘0.00623)
...
10íšŒ: â†’ 0.99142
20íšŒ: â†’ 0.99793
```

#### 2. Evidence ëˆ„ì 

- ìƒˆë¡œìš´ ì¦ê±° ë¬¸ì¥ì„ JSON ë°°ì—´ë¡œ ì €ì¥
- ìµœê·¼ 3ê°œê¹Œì§€ë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ íš¨ìœ¨)
- ì¤‘ë³µ ì œê±° (ë™ì¼í•œ ì¦ê±°ëŠ” í•œ ë²ˆë§Œ ì €ì¥)

#### 3. ì„ íƒì  ì»¬ëŸ¼ ì§€ì›

**ê¸°ë³¸ ì»¬ëŸ¼ (í•„ìˆ˜):**
- `confidence`: ì‹ ë¢°ë„ (0.0 ~ 1.0)
- `evidence`: JSON ë°°ì—´ í˜•íƒœì˜ ì¦ê±°

**í™•ì¥ ì»¬ëŸ¼ (ì„ íƒ):**
- `occurrence_count`: ê´€ê³„ê°€ ë°œê²¬ëœ íšŸìˆ˜ (ê¸°ë³¸ê°’: 1)
- `last_verified_at`: ë§ˆì§€ë§‰ ê²€ì¦ ì‹œê° (TIMESTAMP)

### ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ í™•ì¥

**SQL ë§ˆì´ê·¸ë ˆì´ì…˜ (ì„ íƒì‚¬í•­):**

```sql
-- Add reinforcement columns
ALTER TABLE playbook_semantic_relations
ADD COLUMN IF NOT EXISTS occurrence_count INT DEFAULT 1;

ALTER TABLE playbook_semantic_relations
ADD COLUMN IF NOT EXISTS last_verified_at TIMESTAMP DEFAULT NOW();

-- Create lookup index for efficient upsert
CREATE INDEX IF NOT EXISTS idx_semantic_relations_lookup
ON playbook_semantic_relations(source_term_id, target_term_id, predicate);

-- Update existing rows
UPDATE playbook_semantic_relations
SET occurrence_count = 1, last_verified_at = created_at
WHERE occurrence_count IS NULL;
```

**ì‹¤í–‰ ë°©ë²•:**
1. Supabase Dashboard â†’ SQL Editorë¡œ ì´ë™
2. `supabase/migrations/20250121_add_reinforcement_columns.sql` ë‚´ìš© ì‹¤í–‰

### í…ŒìŠ¤íŠ¸

```bash
# 10ê°œ í˜ì´ì§€ ì²˜ë¦¬
python3 test_10_pages.py

# ê°™ì€ í˜ì´ì§€ ë‹¤ì‹œ ì²˜ë¦¬ (reinforcement í™•ì¸)
python3 test_reinforcement.py
```

### ì¥ì 

1. **ë°ì´í„° í’ˆì§ˆ í–¥ìƒ**: ìì£¼ ë“±ì¥í•˜ëŠ” ì¤‘ìš”í•œ ê´€ê³„ëŠ” ë†’ì€ ì‹ ë¢°ë„
2. **ë…¸ì´ì¦ˆ í•„í„°ë§**: ìš°ì—°íˆ í•œ ë²ˆ ë°œê²¬ëœ ê´€ê³„ëŠ” ë‚®ì€ ì‹ ë¢°ë„ ìœ ì§€
3. **ì¦ê±° ê¸°ë°˜**: ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ ë°œê²¬ëœ ì¦ê±°ë¥¼ ëª¨ë‘ ì¶”ì 
4. **ì ì§„ì  í•™ìŠµ**: ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ì •í™•ë„ í–¥ìƒ
5. **ê³¼ì í•© ë°©ì§€**: ì‹ ë¢°ë„ ìƒí•œì„  1.0ìœ¼ë¡œ ìˆ˜ë ´

---

## ë¼ì´ì„ ìŠ¤

MIT License

---

## ê¸°ì—¬

Issues ë° Pull Requests í™˜ì˜í•©ë‹ˆë‹¤!

---

## ì—°ë½ì²˜

í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì˜: [your-email@example.com]
