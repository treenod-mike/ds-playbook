#!/usr/bin/env python3
"""
v2.0 GraphRAG ì±—ë´‡ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- ì›¹ í”Œë«í¼ê³¼ ë™ì¼í•œ êµ¬ì¡°
- ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
- ê´€ê³„ ê·¸ë˜í”„ ê¸°ë°˜ ë‹µë³€ ìƒì„±
"""
import sys
import os
from pathlib import Path

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.shared.config import Config
from supabase import create_client
from openai import OpenAI
from collections import defaultdict
import json

# Color codes for terminal output
class Colors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

class GraphRAGChatbot:
    """GraphRAG ê¸°ë°˜ ëŒ€í™”í˜• ì±—ë´‡"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        print(f"\n{Colors.HEADER}{'='*70}")
        print("PokoPoko v2.0 GraphRAG ì±—ë´‡ í…ŒìŠ¤íŠ¸")
        print(f"{'='*70}{Colors.ENDC}\n")

        # Supabase ì—°ê²°
        print("ğŸ“¡ Supabase ì—°ê²° ì¤‘...")
        self.supabase = create_client(Config.SUPABASE_URL, Config.SUPABASE_KEY)
        print(f"{Colors.OKGREEN}âœ… Supabase ì—°ê²° ì™„ë£Œ{Colors.ENDC}\n")

        # OpenAI ì—°ê²°
        print("ğŸ¤– OpenAI ì—°ê²° ì¤‘...")
        self.openai_client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_BASE_URL", None)
        )
        print(f"{Colors.OKGREEN}âœ… OpenAI ì—°ê²° ì™„ë£Œ{Colors.ENDC}\n")

        # ëŒ€í™” íˆìŠ¤í† ë¦¬
        self.conversation_history = []
        self.context_terms = set()  # ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ìš©ì–´ë“¤
        self.context_graph = {"nodes": [], "edges": []}  # ëˆ„ì  ê·¸ë˜í”„

        # ë°ì´í„° ë¡œë“œ
        self._load_ontology_data()

    def _load_ontology_data(self):
        """ì˜¨í†¨ë¡œì§€ ë°ì´í„° ë¡œë“œ"""
        print("ğŸ“š ì˜¨í†¨ë¡œì§€ ë°ì´í„° ë¡œë“œ ì¤‘...")

        # ëª¨ë“  ìš©ì–´ ë¡œë“œ
        terms_result = self.supabase.table('playbook_semantic_terms')\
            .select("id, term, category, definition")\
            .execute()
        self.all_terms = terms_result.data
        self.term_map = {t['term']: t for t in self.all_terms}

        # ì˜¨í†¨ë¡œì§€ ë£° ë¡œë“œ
        rules_result = self.supabase.table('playbook_ontology_rules')\
            .select("subject_type, predicate, object_type, description")\
            .execute()
        self.ontology_rules = rules_result.data

        print(f"{Colors.OKGREEN}âœ… ìš©ì–´ {len(self.all_terms)}ê°œ, ì˜¨í†¨ë¡œì§€ ë£° {len(self.ontology_rules)}ê°œ ë¡œë“œ{Colors.ENDC}\n")

    def find_related_terms(self, user_message):
        """ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ê´€ë ¨ ìš©ì–´ ì¶”ì¶œ"""
        mentioned_terms = []
        seen_terms = set()

        for term_data in self.all_terms:
            if term_data['term'] in user_message:
                term_key = f"{term_data['term']}_{term_data['category']}"
                if term_key not in seen_terms:
                    seen_terms.add(term_key)
                    mentioned_terms.append(term_data)
                    self.context_terms.add(term_data['term'])

        return mentioned_terms

    def get_subgraph(self, center_term, radius=2):
        """ì¤‘ì‹¬ ìš©ì–´ ê¸°ë°˜ ì„œë¸Œê·¸ë˜í”„ ì¶”ì¶œ (hop ê²½ë¡œ ì¶”ì )"""
        # ì¤‘ì‹¬ ìš©ì–´ì˜ ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        center_terms = self.supabase.table('playbook_semantic_terms')\
            .select("id, term, category")\
            .eq("term", center_term)\
            .execute()

        if not center_terms.data:
            return {
                "nodes": [],
                "edges": [],
                "reasoning_chain": [],
                "hop_paths": [],
                "traversal_log": []
            }

        center_ids = [t['id'] for t in center_terms.data]

        # BFSë¡œ ê´€ê³„ íƒìƒ‰ (hop ê²½ë¡œ ì¶”ì )
        visited_nodes = {}
        visited_edges = {}
        hop_paths = []  # ê° hop ê²½ë¡œ ì €ì¥
        traversal_log = []  # íƒìƒ‰ ë¡œê·¸

        queue = [(center_id, 0, [center_term]) for center_id in center_ids]  # (id, depth, path)

        hop_count = {0: 0, 1: 0, 2: 0}

        while queue:
            current_id, depth, path = queue.pop(0)

            if depth >= radius:
                continue

            # Outgoing edges (source)
            outgoing = self.supabase.table('playbook_semantic_relations')\
                .select("id, source_term_id, target_term_id, predicate, confidence")\
                .eq("source_term_id", current_id)\
                .gte("confidence", 0.5)\
                .execute()

            for edge in outgoing.data:
                edge_key = f"{edge['source_term_id']}_{edge['predicate']}_{edge['target_term_id']}"
                if edge_key not in visited_edges:
                    visited_edges[edge_key] = edge
                    hop_count[depth + 1] += 1

                    # Get target term name
                    target_node = self.supabase.table('playbook_semantic_terms')\
                        .select("term, category")\
                        .eq("id", edge['target_term_id'])\
                        .limit(1)\
                        .execute()

                    if target_node.data:
                        target_term = target_node.data[0]['term']
                        new_path = path + [target_term]

                        # Record hop path
                        hop_paths.append({
                            "hop": depth + 1,
                            "path": " â†’ ".join(new_path),
                            "predicate": edge['predicate'],
                            "confidence": edge['confidence']
                        })

                        queue.append((edge['target_term_id'], depth + 1, new_path))

            # Incoming edges (target)
            incoming = self.supabase.table('playbook_semantic_relations')\
                .select("id, source_term_id, target_term_id, predicate, confidence")\
                .eq("target_term_id", current_id)\
                .gte("confidence", 0.5)\
                .execute()

            for edge in incoming.data:
                edge_key = f"{edge['source_term_id']}_{edge['predicate']}_{edge['target_term_id']}"
                if edge_key not in visited_edges:
                    visited_edges[edge_key] = edge
                    hop_count[depth + 1] += 1

                    # Get source term name
                    source_node = self.supabase.table('playbook_semantic_terms')\
                        .select("term, category")\
                        .eq("id", edge['source_term_id'])\
                        .limit(1)\
                        .execute()

                    if source_node.data:
                        source_term = source_node.data[0]['term']
                        new_path = path + [source_term]

                        # Record hop path
                        hop_paths.append({
                            "hop": depth + 1,
                            "path": " â†’ ".join(new_path),
                            "predicate": edge['predicate'],
                            "confidence": edge['confidence']
                        })

                        queue.append((edge['source_term_id'], depth + 1, new_path))

        # Traversal log
        traversal_log = [
            f"Hop 0 (ì‹œì‘): {center_term}",
            f"Hop 1: {hop_count[1]}ê°œ ê´€ê³„ ë°œê²¬",
            f"Hop 2: {hop_count[2]}ê°œ ê´€ê³„ ë°œê²¬"
        ]

        # ë…¸ë“œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        all_node_ids = set()
        for edge in visited_edges.values():
            all_node_ids.add(edge['source_term_id'])
            all_node_ids.add(edge['target_term_id'])

        if not all_node_ids:
            return {
                "nodes": [],
                "edges": [],
                "reasoning_chain": [],
                "hop_paths": [],
                "traversal_log": traversal_log
            }

        nodes_result = self.supabase.table('playbook_semantic_terms')\
            .select("id, term, category")\
            .in_("id", list(all_node_ids))\
            .execute()

        node_map = {n['id']: n for n in nodes_result.data}

        # Build reasoning chain
        unique_edges = {}
        for edge in visited_edges.values():
            source_term = node_map.get(edge['source_term_id'], {}).get('term', '')
            target_term = node_map.get(edge['target_term_id'], {}).get('term', '')

            if source_term and target_term:
                edge_key = f"{source_term}_{edge['predicate']}_{target_term}"
                if edge_key not in unique_edges or edge['confidence'] > unique_edges[edge_key]['confidence']:
                    unique_edges[edge_key] = {
                        'source': source_term,
                        'predicate': edge['predicate'],
                        'target': target_term,
                        'confidence': edge['confidence']
                    }

        reasoning_chain = [
            f"{e['source']} â†’ [{e['predicate']}] â†’ {e['target']} (ì‹ ë¢°ë„: {e['confidence']:.2f})"
            for e in sorted(unique_edges.values(), key=lambda x: x['confidence'], reverse=True)[:10]
        ]

        return {
            "nodes": nodes_result.data,
            "edges": list(visited_edges.values()),
            "unique_edges": list(unique_edges.values()),
            "reasoning_chain": reasoning_chain,
            "hop_paths": sorted(hop_paths, key=lambda x: (x['hop'], -x['confidence']))[:15],  # Top 15 paths
            "traversal_log": traversal_log
        }

    def build_graph_context(self, mentioned_terms, subgraph):
        """ê·¸ë˜í”„ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        if not mentioned_terms:
            return ""

        center_term = mentioned_terms[0]['term']

        context = f"\n\n## ğŸ¯ ì§€ì‹ ê·¸ë˜í”„ ì •ë³´\n\n"
        context += f"**ì¤‘ì‹¬ ê°œë…**: {center_term}\n\n"

        # 1. ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ (ì´ì „ì— ì–¸ê¸‰ëœ ìš©ì–´ë“¤)
        if len(self.context_terms) > 1:
            context += f"**ëŒ€í™” ë§¥ë½** (ì´ì „ ì–¸ê¸‰ ìš©ì–´):\n"
            for term in list(self.context_terms)[-5:]:  # ìµœê·¼ 5ê°œ
                if term in self.term_map:
                    t = self.term_map[term]
                    context += f"- {term} ({t['category']})\n"
            context += "\n"

        # 2. ì˜¨í†¨ë¡œì§€ ë£° (ìƒ˜í”Œ)
        context += "**ì˜¨í†¨ë¡œì§€ ë£°** (ì¶”ë¡  ê°€ëŠ¥í•œ ê´€ê³„ íƒ€ì…):\n"
        for rule in self.ontology_rules[:15]:
            context += f"- {rule['subject_type']} --[{rule['predicate']}]--> {rule['object_type']}: {rule['description']}\n"

        # 3. ê´€ë ¨ ê°œë…ë“¤
        unique_nodes = {}
        for node in subgraph['nodes']:
            term_key = f"{node['term']}_{node['category']}"
            if term_key not in unique_nodes:
                unique_nodes[term_key] = node

        context += f"\n**ê´€ë ¨ ê°œë…ë“¤** (ì¤‘ë³µ ì œê±°, {len(unique_nodes)}ê°œ):\n"
        for node in list(unique_nodes.values())[:15]:
            context += f"- {node['term']} ({node['category']})\n"

        # 4. ì‹¤ì œ ê´€ê³„
        if subgraph['unique_edges']:
            context += f"\n**ê´€ê³„** (ì‹¤ì œ ë°ì´í„°, ì¤‘ë³µ ì œê±°, {len(subgraph['unique_edges'])}ê°œ):\n"
            for edge in subgraph['unique_edges'][:20]:
                context += f"- {edge['source']} â†’ {edge['predicate']} â†’ {edge['target']} (ì‹ ë¢°ë„: {edge['confidence']:.2f})\n"

        # 5. ì¶”ë¡  ì²´ì¸ (ê°€ë…ì„± ë†’ì€ í˜•íƒœ)
        if subgraph['reasoning_chain']:
            context += f"\n**ì¶”ë¡  ì²´ì¸** (Top 5):\n"
            for chain in subgraph['reasoning_chain'][:5]:
                context += f"  {chain}\n"

        return context

    def generate_system_prompt(self, graph_context):
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        if graph_context:
            return f"""ë‹¹ì‹ ì€ PokoPoko ê²Œì„ì˜ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ë¶„ì„í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” Supabaseì—ì„œ ë¡œë“œí•œ ì§€ì‹ ê·¸ë˜í”„ ë°ì´í„°ì…ë‹ˆë‹¤:

{graph_context}

**ë‹¹ì‹ ì˜ ì—­í• **:

1. **ëŒ€í™” ë§¥ë½ ìœ ì§€**:
   - ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ìš©ì–´ë“¤ì„ ê¸°ì–µí•˜ê³  ì—°ê²°
   - ì‚¬ìš©ìê°€ "ê·¸ëŸ¼", "ê·¸ê±°", "ê·¸ê²ƒ" ë“± ì§€ì‹œì–´ë¥¼ ì‚¬ìš©í•˜ë©´ ëŒ€í™” ë§¥ë½ì—ì„œ ì¶”ë¡ 
   - ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ ìœ ì§€

2. **ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ì¶”ë¡ **:
   - ì‹¤ì œ ê´€ê³„ ë°ì´í„°ë¥¼ ì˜¨í†¨ë¡œì§€ ë£°ê³¼ ë§¤ì¹­í•˜ì—¬ ì˜ë¯¸ íŒŒì•…
   - ì˜ˆ: "ë™ì  ë‚œì´ë„ --[balances]--> ìœ ì € ì‹¤ë ¥"
     â†’ "ë™ì  ë‚œì´ë„ëŠ” ìœ ì € ì‹¤ë ¥ì— ë§ì¶° ê· í˜•ì„ ë§ì¶¥ë‹ˆë‹¤"

3. **ê´€ê³„ ì²´ì¸ í™œìš©**:
   - ì—¬ëŸ¬ ê´€ê³„ë¥¼ ì—°ê²°í•˜ì—¬ ì‹¬ì¸µì ì¸ ì¸ì‚¬ì´íŠ¸ ì œê³µ
   - ì˜ˆ: "ë™ì  ë‚œì´ë„ â†’ maintains â†’ ëª°ì… â†’ boosts â†’ ë¦¬í…ì…˜"
     â†’ "ë™ì  ë‚œì´ë„ê°€ ëª°ì…ì„ ìœ ì§€í•˜ê³ , ì´ëŠ” ë¦¬í…ì…˜ í–¥ìƒìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤"

4. **ìì—°ìŠ¤ëŸ¬ìš´ ì„¤ëª…**:
   - ê´€ê³„ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ê³ , ì˜ë¯¸ë¥¼ ì¶”ë¡ í•´ì„œ í’€ì–´ì„œ ì„¤ëª…
   - ê²Œì„ í”Œë ˆì´ ê´€ì ì—ì„œ ì‹¤ìš©ì ì¸ ë‹µë³€
   - ì‹ ë¢°ë„ê°€ ë†’ì€(0.8+) ê´€ê³„ ìš°ì„  í™œìš©

5. **ëŒ€í™”í˜• ì‘ë‹µ**:
   - ì§§ê³  ëª…í™•í•˜ê²Œ (2-4ë¬¸ì¥)
   - í•„ìš”ì‹œ ì¶”ê°€ ì§ˆë¬¸ ìœ ë„: "~ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"
   - ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í†¤

**ì¤‘ìš”**:
- ê¸°ìˆ ì ì¸ ìš©ì–´(predicate, confidence ë“±)ëŠ” ì‚¬ìš©ìì—ê²Œ ë…¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”
- ì˜¨í†¨ë¡œì§€ ë£°ì€ ì¶”ë¡ ì˜ ê·¼ê±°ë¡œë§Œ ì‚¬ìš© (ì§ì ‘ ì–¸ê¸‰ X)
- ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ ì†”ì§í•˜ê²Œ: "í˜„ì¬ ê·¸ë˜í”„ì— ê´€ê³„ê°€ ì—†ë„¤ìš”"
"""
        else:
            return """ë‹¹ì‹ ì€ PokoPoko ê²Œì„ì— ëŒ€í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

í˜„ì¬ ì§ˆë¬¸í•˜ì‹  ë‚´ìš©ì— ëŒ€í•œ ì§€ì‹ ê·¸ë˜í”„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.

ë‹µë³€ ë°©ì‹:
- ì§§ê²Œ ì‚¬ê³¼í•˜ê³ 
- ë‹µë³€ ê°€ëŠ¥í•œ ì£¼ì œ ì•ˆë‚´ (ì˜ˆ: "ìŠ¤í…Œì´ì§€, ë¯¸ì…˜, í´ë¡œë²„ ë“±ì— ëŒ€í•´ì„œëŠ” ë‹µë³€í•  ìˆ˜ ìˆì–´ìš”!")
- ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ
"""

    def chat(self, user_message):
        """ëŒ€í™” ì²˜ë¦¬ (ìƒì„¸ ì¶”ë¡  ê³¼ì • í¬í•¨)"""
        print(f"\n{Colors.HEADER}{'='*70}")
        print(f"[ê²€ìƒ‰ ë° ì¶”ë¡  í”„ë¡œì„¸ìŠ¤]")
        print(f"{'='*70}{Colors.ENDC}\n")

        # 1. ê´€ë ¨ ìš©ì–´ ì¶”ì¶œ
        print(f"{Colors.OKCYAN}1ï¸âƒ£ ìš©ì–´ ë§¤ì¹­ ë‹¨ê³„{Colors.ENDC}")
        print(f"   ì‚¬ìš©ì ì§ˆë¬¸: \"{user_message}\"")
        mentioned_terms = self.find_related_terms(user_message)

        if not mentioned_terms:
            print(f"   {Colors.WARNING}âš ï¸ ê´€ë ¨ ìš©ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.{Colors.ENDC}")
            print(f"\n{Colors.FAIL}âŒ ì§ˆë¬¸í•˜ì‹  ìš©ì–´ê°€ DBì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.{Colors.ENDC}")
            print("ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ì‹œë„í•´ë³´ì„¸ìš” (ì˜ˆ: 'ìŠ¤í…Œì´ì§€', 'ë¯¸ì…˜', 'í´ë¡œë²„' ë“±)\n")
            return

        print(f"   {Colors.OKGREEN}âœ… {len(mentioned_terms)}ê°œ ìš©ì–´ ë°œê²¬:{Colors.ENDC}")
        for term in mentioned_terms[:5]:
            print(f"      - {term['term']} ({term['category']})")
        print()

        # 2. ì„œë¸Œê·¸ë˜í”„ ì¶”ì¶œ
        center_term = mentioned_terms[0]['term']
        print(f"{Colors.OKCYAN}2ï¸âƒ£ ê·¸ë˜í”„ íƒìƒ‰ ë‹¨ê³„ (BFS){Colors.ENDC}")
        print(f"   ì¤‘ì‹¬ ìš©ì–´: {center_term}")
        print(f"   íƒìƒ‰ ë°˜ê²½: 2-hop")

        subgraph = self.get_subgraph(center_term, radius=2)

        # Traversal log ì¶œë ¥
        print(f"\n   {Colors.HEADER}[ê·¸ë˜í”„ íƒìƒ‰ ê²½ë¡œ]{Colors.ENDC}")
        for log in subgraph['traversal_log']:
            print(f"   {log}")

        print(f"\n   {Colors.OKGREEN}âœ… ì´ ë…¸ë“œ {len(subgraph['nodes'])}ê°œ, ê´€ê³„ {len(subgraph['edges'])}ê°œ ë°œê²¬{Colors.ENDC}\n")

        if len(subgraph['edges']) == 0:
            print(f"   {Colors.WARNING}âš ï¸ '{center_term}' ìš©ì–´ëŠ” ì¡´ì¬í•˜ì§€ë§Œ ì—°ê²°ëœ ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.{Colors.ENDC}")
            print("   Phase 2ë¥¼ ì¬ì‹¤í–‰í•˜ê±°ë‚˜ ë‹¤ë¥¸ ìš©ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.\n")
            return

        # 3. Hop ê²½ë¡œ ì‹œê°í™”
        print(f"{Colors.OKCYAN}3ï¸âƒ£ Hop ê²½ë¡œ ë¶„ì„{Colors.ENDC}")

        hop1_paths = [p for p in subgraph['hop_paths'] if p['hop'] == 1]
        hop2_paths = [p for p in subgraph['hop_paths'] if p['hop'] == 2]

        if hop1_paths:
            print(f"\n   {Colors.HEADER}[Hop 1 ê²½ë¡œ] (1ë‹¨ê³„ ê´€ê³„, {len(hop1_paths)}ê°œ){Colors.ENDC}")
            for i, path_info in enumerate(hop1_paths[:5], 1):
                print(f"   {i}. {path_info['path']}")
                print(f"      â””â”€ Predicate: {path_info['predicate']} (ì‹ ë¢°ë„: {path_info['confidence']:.2f})")

        if hop2_paths:
            print(f"\n   {Colors.HEADER}[Hop 2 ê²½ë¡œ] (2ë‹¨ê³„ ê´€ê³„, {len(hop2_paths)}ê°œ){Colors.ENDC}")
            for i, path_info in enumerate(hop2_paths[:5], 1):
                print(f"   {i}. {path_info['path']}")
                print(f"      â””â”€ Predicate: {path_info['predicate']} (ì‹ ë¢°ë„: {path_info['confidence']:.2f})")

        # 4. ì¶”ë¡  ì²´ì¸ (ì˜¨í†¨ë¡œì§€ ê¸°ë°˜)
        print(f"\n{Colors.OKCYAN}4ï¸âƒ£ ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ì¶”ë¡  ì²´ì¸{Colors.ENDC}")
        if subgraph['reasoning_chain']:
            print(f"   {Colors.HEADER}[Top 5 ì¶”ë¡  ê²½ë¡œ]{Colors.ENDC}")
            for i, chain in enumerate(subgraph['reasoning_chain'][:5], 1):
                print(f"   {i}. {chain}")
        print()

        # 5. ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        print(f"{Colors.OKCYAN}5ï¸âƒ£ LLM ì»¨í…ìŠ¤íŠ¸ ìƒì„±{Colors.ENDC}")
        graph_context = self.build_graph_context(mentioned_terms, subgraph)

        context_stats = {
            "ëŒ€í™” ë§¥ë½ ìš©ì–´": len(self.context_terms),
            "ì˜¨í†¨ë¡œì§€ ë£°": len(self.ontology_rules),
            "ê´€ë ¨ ê°œë…": len(subgraph['nodes']),
            "ì‹¤ì œ ê´€ê³„": len(subgraph['unique_edges'])
        }

        print(f"   {Colors.OKGREEN}âœ… ì»¨í…ìŠ¤íŠ¸ ìš”ì†Œ:{Colors.ENDC}")
        for key, value in context_stats.items():
            print(f"      - {key}: {value}ê°œ")
        print()

        # 6. LLM í˜¸ì¶œ
        print(f"{Colors.OKCYAN}6ï¸âƒ£ GPT-4 ì‘ë‹µ ìƒì„±{Colors.ENDC}")
        print(f"   ëª¨ë¸: gpt-4o")
        print(f"   ì˜¨í†¨ë¡œì§€ ë£° ê¸°ë°˜ ì¶”ë¡  í™œì„±í™”")
        print(f"   ëŒ€í™” íˆìŠ¤í† ë¦¬: {len(self.conversation_history) // 2}í„´ ìœ ì§€\n")

        system_prompt = self.generate_system_prompt(graph_context)

        messages = [{"role": "system", "content": system_prompt}]

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 5í„´)
        for msg in self.conversation_history[-10:]:  # ìµœê·¼ 5í„´ (user+assistant = 10ê°œ)
            messages.append(msg)

        # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€
        messages.append({"role": "user", "content": user_message})

        # OpenAI API í˜¸ì¶œ
        response = self.openai_client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            max_tokens=1024,
            temperature=0.7
        )

        assistant_message = response.choices[0].message.content

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        self.conversation_history.append({"role": "user", "content": user_message})
        self.conversation_history.append({"role": "assistant", "content": assistant_message})

        # 7. ìµœì¢… ë‹µë³€ ë° ê·¼ê±°
        print(f"{Colors.HEADER}{'='*70}")
        print(f"[ìµœì¢… ë‹µë³€ ë° ê·¼ê±°]")
        print(f"{'='*70}{Colors.ENDC}\n")

        print(f"{Colors.BOLD}[AI ì–´ì‹œìŠ¤í„´íŠ¸]{Colors.ENDC}\n")
        print(assistant_message)

        print(f"\n{Colors.HEADER}[ë‹µë³€ ê·¼ê±°]{Colors.ENDC}")
        print(f"  - ì‚¬ìš©ëœ ê´€ê³„: {len(subgraph['unique_edges'])}ê°œ")
        print(f"  - íƒìƒ‰ ê¹Šì´: 2-hop")
        print(f"  - ìµœê³  ì‹ ë¢°ë„ ê´€ê³„: {subgraph['unique_edges'][0]['confidence']:.2f}" if subgraph['unique_edges'] else "  - N/A")
        print(f"  - ëŒ€í™” ì»¨í…ìŠ¤íŠ¸: {', '.join(list(self.context_terms)[-3:])}" if len(self.context_terms) > 1 else "  - ì—†ìŒ")

        print(f"\n{Colors.BOLD}{'â”'*70}{Colors.ENDC}\n")

    def run(self):
        """ëŒ€í™”í˜• ë£¨í”„ ì‹¤í–‰"""
        print(f"{Colors.HEADER}ğŸ’¬ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.{Colors.ENDC}\n")

        # í™˜ì˜ ë©”ì‹œì§€
        print(f"{Colors.OKGREEN}ì•ˆë…•í•˜ì„¸ìš”! PokoPoko ê²Œì„ì˜ ì§€ì‹ ê·¸ë˜í”„ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.{Colors.ENDC}")
        print(f"{Colors.OKGREEN}ê²Œì„ ë©”ì¹´ë‹‰, ì´ë²¤íŠ¸, UX, ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”!{Colors.ENDC}\n")

        while True:
            try:
                # ì‚¬ìš©ì ì…ë ¥
                user_input = input(f"{Colors.OKCYAN}You: {Colors.ENDC}").strip()

                if not user_input:
                    continue

                if user_input.lower() in ['exit', 'quit', 'ì¢…ë£Œ']:
                    print(f"\n{Colors.OKGREEN}ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!{Colors.ENDC}\n")
                    break

                # íŠ¹ìˆ˜ ëª…ë ¹ì–´
                if user_input.lower() == 'history':
                    print(f"\n{Colors.HEADER}[ëŒ€í™” íˆìŠ¤í† ë¦¬]{Colors.ENDC}")
                    for i, msg in enumerate(self.conversation_history, 1):
                        role = "ì‚¬ìš©ì" if msg['role'] == 'user' else "AI"
                        print(f"{i}. [{role}] {msg['content'][:50]}...")
                    print()
                    continue

                if user_input.lower() == 'context':
                    print(f"\n{Colors.HEADER}[ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìš©ì–´]{Colors.ENDC}")
                    print(f"{', '.join(self.context_terms)}\n")
                    continue

                # ëŒ€í™” ì²˜ë¦¬
                self.chat(user_input)

            except KeyboardInterrupt:
                print(f"\n\n{Colors.OKGREEN}ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!{Colors.ENDC}\n")
                break
            except Exception as e:
                print(f"\n{Colors.FAIL}âŒ ì˜¤ë¥˜ ë°œìƒ: {e}{Colors.ENDC}\n")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    chatbot = GraphRAGChatbot()
    chatbot.run()

if __name__ == "__main__":
    main()
